{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "\n",
    "\n",
    "import os\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "from torch.nn import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to classifier_data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 7386158.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting classifier_data\\MNIST\\raw\\train-images-idx3-ubyte.gz to classifier_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to classifier_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 280062.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting classifier_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to classifier_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to classifier_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1585619.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting classifier_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to classifier_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to classifier_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4544496.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting classifier_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to classifier_data\\MNIST\\raw\n",
      "\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: classifier_data\n",
      "    Split: Train \n",
      "\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: classifier_data\n",
      "    Split: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Dataset\n",
    "\n",
    "### Download\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST('classifier_data', train=True, download=True)\n",
    "test_dataset  = torchvision.datasets.MNIST('classifier_data', train=False, download=True)\n",
    "\n",
    "# Datsets\n",
    "\n",
    "print(train_dataset, \"\\n\")\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple: (<PIL.Image.Image image mode=L size=28x28 at 0x22F9EDFCEB0>, 5)\n",
      "\n",
      "Image format: <PIL.Image.Image image mode=L size=28x28 at 0x22F9EE41670>\n",
      "\n",
      "Sample at index: 0\n",
      "\n",
      "Label: 7\n",
      "\n",
      "Image:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How to get an image (PIL image) and the corresponding label\n",
    "\n",
    "sample_index = 0\n",
    "image = test_dataset[sample_index][0]\n",
    "label = test_dataset[sample_index][1]\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(image, cmap='gist_gray')\n",
    "print(f\"Tuple:\", train_dataset[sample_index])\n",
    "print(f\"\\nImage format:\", train_dataset[sample_index][0])\n",
    "print(f\"\\nSample at index: {sample_index}\")\n",
    "print(f\"\\nLabel: {label}\")\n",
    "print(\"\\nImage:\\n\")\n",
    "\n",
    "# Some image samples\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for sample_index in range(4):\n",
    "  im = train_dataset[sample_index][0]\n",
    "  lab = train_dataset[sample_index][1]\n",
    "\n",
    "  plt.subplot(2,2,sample_index+1)\n",
    "  plt.title(f\"Label: {lab}\")\n",
    "  plt.imshow(im, cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Data and splitting (train and validation sets)\"\"\"\n",
    "\n",
    "# Tensor transformation of all dataset\n",
    "\n",
    "train_trans = transforms.ToTensor()\n",
    "test_trans = transforms.ToTensor()\n",
    "\n",
    "train_dataset.transform = train_trans\n",
    "test_dataset.transform = test_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor shape: torch.Size([1, 28, 28])\n",
      "\n",
      "Tensor label at index 3: 1\n",
      "\n",
      "Tensor shape: torch.Size([1, 28, 28])\n",
      "\n",
      "Tensor label at index 3: 0\n",
      "Train set length: 50000\n",
      "\n",
      "Validation set length: 10000\n",
      "\n",
      "Test set length: 10000\n",
      "\n",
      "Whole train set for the train of the best model: 60000\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "print(f\"\\nTensor shape: {train_dataset[sample_index][0].shape}\")\n",
    "print(f\"\\nTensor label at index {sample_index}: {train_dataset[sample_index][1]}\")\n",
    "\n",
    "# Test Set\n",
    "print(f\"\\nTensor shape:\", test_dataset[sample_index][0].shape)\n",
    "print(f\"\\nTensor label at index {sample_index}: {test_dataset[sample_index][1]}\")\n",
    "\n",
    "# Split train (50000 samples) and validation set (10000 samples) \n",
    "\n",
    "torch.manual_seed(0)\n",
    "train_dataset_new, val_dataset = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "print(f\"Train set length: {len(train_dataset_new)}\")\n",
    "print(f\"\\nValidation set length: {len(val_dataset)}\")\n",
    "print(f\"\\nTest set length: {len(test_dataset)}\")\n",
    "print(f\"\\nWhole train set for the train of the best model: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=50, shuffle=True,  num_workers=2)\n",
    "train_dataloader_new = DataLoader(dataset=train_dataset_new, batch_size=50, shuffle=True,  num_workers=2)\n",
    "validation_dataloader   = DataLoader(dataset=val_dataset,   batch_size=len(val_dataset),  shuffle=False, num_workers=2) \n",
    "test_dataloader  = DataLoader(dataset=test_dataset,  batch_size=len(test_dataset),  shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train input batch shape: torch.Size([50, 1, 28, 28])\n",
      "Train label batch shape: torch.Size([50])\n",
      "\n",
      "Validation input batch shape: torch.Size([10000, 1, 28, 28])\n",
      "Validation label batch shape: torch.Size([10000])\n",
      "\n",
      "Test input batch shape: torch.Size([10000, 1, 28, 28])\n",
      "Test label batch shape: torch.Size([10000])\n",
      "\n",
      "Train batch of the train set for the best model:\n",
      "Train input batch shape: torch.Size([50, 1, 28, 28])\n",
      "Train label batch shape: torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# Dimension exploration of dataloaders\n",
    "\n",
    "# Train batch\n",
    "image_batch, label_batch = next(iter(train_dataloader_new))\n",
    "print(f\"\\nTrain input batch shape: {image_batch.shape}\")\n",
    "print(f\"Train label batch shape: {label_batch.shape}\")\n",
    "\n",
    "# Validation batch\n",
    "image_batch, label_batch = next(iter(validation_dataloader))\n",
    "print(f\"\\nValidation input batch shape: {image_batch.shape}\")\n",
    "print(f\"Validation label batch shape: {label_batch.shape}\")\n",
    "\n",
    "# Test batch\n",
    "image_batch, label_batch = next(iter(test_dataloader))\n",
    "print(f\"\\nTest input batch shape: {image_batch.shape}\")\n",
    "print(f\"Test label batch shape: {label_batch.shape}\")\n",
    "\n",
    "# Train batch (Whole train set)\n",
    "print(\"\\nTrain batch of the train set for the best model:\")\n",
    "image_batch, label_batch = next(iter(train_dataloader))\n",
    "print(f\"Train input batch shape: {image_batch.shape}\")\n",
    "print(f\"Train label batch shape: {label_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Feed forward neural network (FFNN)\n",
    "\n",
    "### Model\n",
    "\"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, Ni, Nh1, Nh2, No, act_func, dropout): # Structure of the network, definition of the structural parameters\n",
    "        \"\"\"\n",
    "        Ni - Input size\n",
    "        Nh1 - Neurons in the first hidden layer\n",
    "        Nh1 - Neurons in the second hidden layer\n",
    "        No - Output size\n",
    "        Activation function \n",
    "        Dropout probability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=Ni, out_features=Nh1)\n",
    "        self.fc2 = nn.Linear(in_features=Nh1, out_features=Nh2)\n",
    "        self.out = nn.Linear(in_features=Nh2, out_features=No)\n",
    "        self.act = act_func\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.act(self.fc1(x)) \n",
    "        x = self.dropout(x)\n",
    "        x = self.act(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def reset_weights(model):\n",
    "        torch.manual_seed(0)\n",
    "        for layer in model.children():\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function FFNN\n",
    "\n",
    "def train_function_FFNN(model, train_dataloader, validation_dataloader, num_epochs, optimizer, loss_function):\n",
    "    \"\"\"\n",
    "    Input: model, train dataloader, validation dataloader, number of epochs, optimizer\n",
    "    Output: list of (batch average) train losses (one for each epoch), list of (batch average) validation losses (one for each epoch)\n",
    "    \"\"\"\n",
    "    torch.manual_seed(0)\n",
    "    model.reset_weights() # Reset of the weights \n",
    "    \n",
    "    train_loss_epochs = []\n",
    "    accuracy_train_epochs = []\n",
    "    \n",
    "    val_loss_epochs = []\n",
    "    accuracy_val_epochs = []\n",
    "\n",
    "    for epoch_num in range(num_epochs):\n",
    "      print(f'-> Epoch {epoch_num + 1}\\n')\n",
    "\n",
    "      # TRAIN\n",
    "      train_loss= []\n",
    "      accuracy_batch_train = []\n",
    "      model.train() # Training mode \n",
    "      for sample_batched in train_dataloader:\n",
    "        \n",
    "        # Move data to device\n",
    "        x_batch = sample_batched[0].to(FFNN_device)\n",
    "        label_batch = sample_batched[1].to(FFNN_device)\n",
    "\n",
    "        # Batch sample reshaping\n",
    "        x_batch = x_batch.view(50, 1, 784) # From [50, 1, 28, 28] to [50, 1, 784]\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(x_batch)\n",
    "\n",
    "        # Output reshaping\n",
    "        out = out.view(50, 10)  # From [50, 1, 10] to [50, 10]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(out, label_batch) \n",
    "\n",
    "        # Backpropagation\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save train loss for this batch\n",
    "        loss_batch = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_batch) \n",
    "\n",
    "        # Prediction for training set\n",
    "        softmax = torch.exp(out).cpu()\n",
    "        prob = list(softmax.detach().numpy())\n",
    "        predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "        # Save accuracy for this batch\n",
    "        accuracy_batch_train.append(accuracy_score(label_batch.cpu(), predictions))\n",
    "\n",
    "      # Save average train loss for this epoch\n",
    "      train_loss = np.mean(train_loss) \n",
    "      print(f\"Train loss: {train_loss}\") \n",
    "      train_loss_epochs.append(train_loss) # List of the losses (= number of epochs) \n",
    "\n",
    "      # Save average accuracy for this epoch\n",
    "      accuracy_batch_train = np.mean(accuracy_batch_train) \n",
    "      print(f\"Accuracy on training set: {accuracy_batch_train}\\n\")\n",
    "      accuracy_train_epochs.append(accuracy_batch_train) # List of the accuracies (= number of epochs) \n",
    "      \n",
    "\n",
    "      # VALIDATION\n",
    "      val_loss = []\n",
    "      accuracy_batch_val = []\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "        for sample_batched in validation_dataloader: # If \"batch_size=len(validation_dataset)\" in validation_loder we have only one value (one iteration for the cycle)\n",
    "\n",
    "            # Move data to device\n",
    "            x_batch = sample_batched[0].to(FFNN_device)\n",
    "            label_batch = sample_batched[1].to(FFNN_device)\n",
    "\n",
    "            # Batch sample reshaping\n",
    "            x_batch = x_batch.view(10000, 1, 784) # From [10000, 1, 28, 28] to [10000, 1, 784]\n",
    "\n",
    "            # Forward pass\n",
    "            out = model(x_batch)\n",
    "\n",
    "            # Output reshaping\n",
    "            out = out.view(10000, 10)  # From [10000, 1, 10] to [10000, 10]\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_function(out, label_batch)\n",
    "\n",
    "            # Save val loss for this batch\n",
    "            loss_batch = loss.detach().cpu().numpy()\n",
    "            val_loss.append(loss_batch)\n",
    "\n",
    "            # Prediction for validation set\n",
    "            softmax = torch.exp(out).cpu()\n",
    "            prob = list(softmax.detach().numpy())\n",
    "            predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "            # Save accuracy for this batch\n",
    "            accuracy_batch_val.append(accuracy_score(label_batch.cpu(), predictions))\n",
    "      \n",
    "        # Save average validation loss for this epoch\n",
    "        val_loss = np.mean(val_loss) # Validation loss calculated after each epoch\n",
    "        print(f\"Validation loss: {val_loss}\") \n",
    "        val_loss_epochs.append(val_loss)\n",
    "\n",
    "        # Save average accuracy for this epoch\n",
    "        accuracy_batch_val = np.mean(accuracy_batch_val) \n",
    "        print(f\"Accuracy on validation set: {accuracy_batch_val}\\n\")\n",
    "        accuracy_val_epochs.append(accuracy_batch_val) # List of the accuracies (= number of epochs) \n",
    "\n",
    "    return train_loss_epochs, accuracy_train_epochs, val_loss_epochs, accuracy_val_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Optimizers\n",
    "\n",
    "#### Adam\n",
    "\"\"\"\n",
    "\n",
    "class Adam_optimizer(optim.Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {} < 0\".format(lr))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid parameter beta_1: {} not in [0; 1)\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid parameter beta_2: {} not in [0; 1)\".format(betas[1]))\n",
    "        if eps < 0.0:\n",
    "            raise ValueError(\"Invalid epsilon value: {} < 0\".format(eps))\n",
    "        if weight_decay < 0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {} < 0\".format(weight_decay))\n",
    "\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        super(Adam_optimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        for group in self.param_groups:\n",
    "            for params in group[\"params\"]:\n",
    "                if params.grad is None:\n",
    "                    continue\n",
    "\n",
    "                grad = params.grad.data\n",
    "                # if grad.is_sparse:\n",
    "                #     raise RuntimeError('We do not deal with sparse gradient.')     #do we need this check?\n",
    "                \n",
    "                state = self.state[params]\n",
    "                if state.get('step', 0) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['m'] = torch.zeros_like(params.data)\n",
    "                    state['v'] = torch.zeros_like(params.data)\n",
    "\n",
    "                m = state['m']\n",
    "                v = state['v']\n",
    "                beta1, beta2 = group['betas']\n",
    "                state['step'] += 1\n",
    "\n",
    "                m = m * beta1 + (1 - beta1) * grad\n",
    "                v = v * beta2 + (1 - beta2) * grad * grad\n",
    "\n",
    "                m_hat = m / (1 - beta1 ** state['step'])\n",
    "                v_hat = v / (1 - beta2 ** state['step'])\n",
    "\n",
    "                params.data -= group['lr'] * m_hat / (v_hat.sqrt() + group['eps'])\n",
    "\n",
    "                state['m'] = m\n",
    "                state['v'] = v\n",
    "\n",
    "        return None      # return loss = closure() but we don't use closure so it is None\n",
    "\n",
    "\"\"\"#### Adagrad\"\"\"\n",
    "\n",
    "class AdaGrad_optimizer(optim.Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, eps=1e-8, weight_decay=0, lr_decay=0.5):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {} < 0\".format(lr))\n",
    "        if eps < 0.0:\n",
    "            raise ValueError(\"Invalid epsilon value: {} < 0\".format(eps))\n",
    "        if weight_decay < 0.0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {} < 0\".format(weight_decay))\n",
    "        if lr_decay < 0.0:\n",
    "            raise ValueError(\"Invalid lr_decay value: {} < 0\".format(lr_decay))\n",
    "\n",
    "        defaults = dict(lr=lr, eps=eps, weight_decay=weight_decay, lr_decay=lr_decay)\n",
    "        super(AdaGrad_optimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        for group in self.param_groups:\n",
    "            for params in group[\"params\"]:\n",
    "                if params.grad is None:\n",
    "                    continue\n",
    "\n",
    "                grad = params.grad.data\n",
    "                # if grad.is_sparse:\n",
    "                #     raise RuntimeError('We do not deal with sparse gradient.')\n",
    "                \n",
    "                state = self.state[params]\n",
    "                if state.get('step', 0) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['G'] = 0\n",
    "\n",
    "                state['G'] += grad * grad\n",
    "                state['step'] += 1\n",
    "\n",
    "                params.data -= group['lr'] * grad / (state['G'] + group['eps']).sqrt()\n",
    "\n",
    "        return None      # return loss = closure() but we don't use closure so it is None\n",
    "\n",
    "\"\"\"### Random search\"\"\"\n",
    "\n",
    "# Dict of lists of hyperparameters FFNN\n",
    "\n",
    "hyperparam_grid_FFNN = {\"Num_hidd_neurons\": [64, 128], \"Epochs\":[30], \"Act_func\": [nn.ReLU(), nn.Sigmoid()],\n",
    "              \"Optimizer\": [optim.Adam, optim.RMSprop], \"lr\": [0.001, 0.005],  \"Regularizer_L2\": [0, 0.001, 0.0001], \"Dropout\": [0, 0.3]}\n",
    "\n",
    "# Random search FFNN\n",
    "\n",
    "combinations_dict = ParameterGrid(hyperparam_grid_FFNN) # Combinations dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##### MODEL: 1/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0.001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': ReLU()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.5169405937194824\n",
      "Accuracy on training set: 0.8442200000000001\n",
      "\n",
      "Validation loss: 0.27936553955078125\n",
      "Accuracy on validation set: 0.9146\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.3367876410484314\n",
      "Accuracy on training set: 0.89926\n",
      "\n",
      "Validation loss: 0.22509604692459106\n",
      "Accuracy on validation set: 0.9346\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.31480225920677185\n",
      "Accuracy on training set: 0.90722\n",
      "\n",
      "Validation loss: 0.19595715403556824\n",
      "Accuracy on validation set: 0.9408\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.30356624722480774\n",
      "Accuracy on training set: 0.9107000000000001\n",
      "\n",
      "Validation loss: 0.18150995671749115\n",
      "Accuracy on validation set: 0.9459\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.29774871468544006\n",
      "Accuracy on training set: 0.91244\n",
      "\n",
      "Validation loss: 0.18320195376873016\n",
      "Accuracy on validation set: 0.9423\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.30142608284950256\n",
      "Accuracy on training set: 0.91172\n",
      "\n",
      "Validation loss: 0.17237098515033722\n",
      "Accuracy on validation set: 0.9518\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.29071930050849915\n",
      "Accuracy on training set: 0.91574\n",
      "\n",
      "Validation loss: 0.1959131509065628\n",
      "Accuracy on validation set: 0.9427\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.29133355617523193\n",
      "Accuracy on training set: 0.91396\n",
      "\n",
      "Validation loss: 0.1742178052663803\n",
      "Accuracy on validation set: 0.9505\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.2925854027271271\n",
      "Accuracy on training set: 0.91408\n",
      "\n",
      "Validation loss: 0.17071621119976044\n",
      "Accuracy on validation set: 0.9519\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.2930731773376465\n",
      "Accuracy on training set: 0.91364\n",
      "\n",
      "Validation loss: 0.19090113043785095\n",
      "Accuracy on validation set: 0.9421\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.2887403666973114\n",
      "Accuracy on training set: 0.9158399999999999\n",
      "\n",
      "Validation loss: 0.18230070173740387\n",
      "Accuracy on validation set: 0.9442\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.2896971106529236\n",
      "Accuracy on training set: 0.91406\n",
      "\n",
      "Validation loss: 0.19615468382835388\n",
      "Accuracy on validation set: 0.945\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.29340311884880066\n",
      "Accuracy on training set: 0.91298\n",
      "\n",
      "Validation loss: 0.17135684192180634\n",
      "Accuracy on validation set: 0.9498\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.29243004322052\n",
      "Accuracy on training set: 0.91512\n",
      "\n",
      "Validation loss: 0.19346848130226135\n",
      "Accuracy on validation set: 0.9428\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.28824707865715027\n",
      "Accuracy on training set: 0.9152\n",
      "\n",
      "Validation loss: 0.23314149677753448\n",
      "Accuracy on validation set: 0.9317\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.2897946238517761\n",
      "Accuracy on training set: 0.9130199999999999\n",
      "\n",
      "Validation loss: 0.20449697971343994\n",
      "Accuracy on validation set: 0.939\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.2929803431034088\n",
      "Accuracy on training set: 0.9151199999999999\n",
      "\n",
      "Validation loss: 0.19083966314792633\n",
      "Accuracy on validation set: 0.9429\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.2898859977722168\n",
      "Accuracy on training set: 0.91604\n",
      "\n",
      "Validation loss: 0.1837473064661026\n",
      "Accuracy on validation set: 0.9455\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.2888507544994354\n",
      "Accuracy on training set: 0.91396\n",
      "\n",
      "Validation loss: 0.19548915326595306\n",
      "Accuracy on validation set: 0.94\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.2846170663833618\n",
      "Accuracy on training set: 0.91584\n",
      "\n",
      "Validation loss: 0.1701851338148117\n",
      "Accuracy on validation set: 0.9518\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.2895360589027405\n",
      "Accuracy on training set: 0.916\n",
      "\n",
      "Validation loss: 0.18890875577926636\n",
      "Accuracy on validation set: 0.9427\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.28512701392173767\n",
      "Accuracy on training set: 0.9163600000000002\n",
      "\n",
      "Validation loss: 0.16813954710960388\n",
      "Accuracy on validation set: 0.9506\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.28695306181907654\n",
      "Accuracy on training set: 0.91546\n",
      "\n",
      "Validation loss: 0.19556565582752228\n",
      "Accuracy on validation set: 0.94\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.289871484041214\n",
      "Accuracy on training set: 0.91508\n",
      "\n",
      "Validation loss: 0.19086891412734985\n",
      "Accuracy on validation set: 0.9414\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.2884340286254883\n",
      "Accuracy on training set: 0.91668\n",
      "\n",
      "Validation loss: 0.16551919281482697\n",
      "Accuracy on validation set: 0.9528\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.28909832239151\n",
      "Accuracy on training set: 0.91526\n",
      "\n",
      "Validation loss: 0.19381554424762726\n",
      "Accuracy on validation set: 0.9426\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.2927161157131195\n",
      "Accuracy on training set: 0.9144000000000001\n",
      "\n",
      "Validation loss: 0.18337084352970123\n",
      "Accuracy on validation set: 0.9482\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.29051339626312256\n",
      "Accuracy on training set: 0.9157000000000001\n",
      "\n",
      "Validation loss: 0.19437409937381744\n",
      "Accuracy on validation set: 0.9419\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.2875271737575531\n",
      "Accuracy on training set: 0.9151200000000002\n",
      "\n",
      "Validation loss: 0.1700052171945572\n",
      "Accuracy on validation set: 0.9478\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.28976988792419434\n",
      "Accuracy on training set: 0.9145\n",
      "\n",
      "Validation loss: 0.1662338525056839\n",
      "Accuracy on validation set: 0.9468\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.1662338525056839\n",
      "Final accuracy on validation set: 0.9468\n",
      "\n",
      "\n",
      "##### MODEL: 2/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': ReLU()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.42366260290145874\n",
      "Accuracy on training set: 0.8723\n",
      "\n",
      "Validation loss: 0.1800255924463272\n",
      "Accuracy on validation set: 0.9459\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.2012515515089035\n",
      "Accuracy on training set: 0.9392\n",
      "\n",
      "Validation loss: 0.1336081475019455\n",
      "Accuracy on validation set: 0.9594\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.15615853667259216\n",
      "Accuracy on training set: 0.95412\n",
      "\n",
      "Validation loss: 0.12050244212150574\n",
      "Accuracy on validation set: 0.9639\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.13494107127189636\n",
      "Accuracy on training set: 0.95818\n",
      "\n",
      "Validation loss: 0.09931765496730804\n",
      "Accuracy on validation set: 0.9704\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.11597125977277756\n",
      "Accuracy on training set: 0.96478\n",
      "\n",
      "Validation loss: 0.08845275640487671\n",
      "Accuracy on validation set: 0.9736\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.10703709721565247\n",
      "Accuracy on training set: 0.9663800000000001\n",
      "\n",
      "Validation loss: 0.086800217628479\n",
      "Accuracy on validation set: 0.9736\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.09838729351758957\n",
      "Accuracy on training set: 0.9702600000000001\n",
      "\n",
      "Validation loss: 0.08787309378385544\n",
      "Accuracy on validation set: 0.9744\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.09243366867303848\n",
      "Accuracy on training set: 0.9714200000000001\n",
      "\n",
      "Validation loss: 0.08291217684745789\n",
      "Accuracy on validation set: 0.975\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.08218368887901306\n",
      "Accuracy on training set: 0.9735000000000001\n",
      "\n",
      "Validation loss: 0.08980202674865723\n",
      "Accuracy on validation set: 0.9738\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.0821366012096405\n",
      "Accuracy on training set: 0.9743000000000002\n",
      "\n",
      "Validation loss: 0.08832727372646332\n",
      "Accuracy on validation set: 0.974\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.0757450982928276\n",
      "Accuracy on training set: 0.9753200000000001\n",
      "\n",
      "Validation loss: 0.08133182674646378\n",
      "Accuracy on validation set: 0.9765\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.07362515479326248\n",
      "Accuracy on training set: 0.97696\n",
      "\n",
      "Validation loss: 0.08105025440454483\n",
      "Accuracy on validation set: 0.976\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.06904708594083786\n",
      "Accuracy on training set: 0.97752\n",
      "\n",
      "Validation loss: 0.085941843688488\n",
      "Accuracy on validation set: 0.9757\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.06777409464120865\n",
      "Accuracy on training set: 0.9788800000000001\n",
      "\n",
      "Validation loss: 0.08539561927318573\n",
      "Accuracy on validation set: 0.9773\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.06553389132022858\n",
      "Accuracy on training set: 0.9792000000000001\n",
      "\n",
      "Validation loss: 0.08104413747787476\n",
      "Accuracy on validation set: 0.9769\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.06307342648506165\n",
      "Accuracy on training set: 0.9797600000000001\n",
      "\n",
      "Validation loss: 0.08234957605600357\n",
      "Accuracy on validation set: 0.9778\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.060019105672836304\n",
      "Accuracy on training set: 0.9809600000000002\n",
      "\n",
      "Validation loss: 0.08364392071962357\n",
      "Accuracy on validation set: 0.9767\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.060906678438186646\n",
      "Accuracy on training set: 0.98072\n",
      "\n",
      "Validation loss: 0.07553449273109436\n",
      "Accuracy on validation set: 0.9789\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.055287476629018784\n",
      "Accuracy on training set: 0.9821000000000001\n",
      "\n",
      "Validation loss: 0.08175764232873917\n",
      "Accuracy on validation set: 0.9778\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.05558106303215027\n",
      "Accuracy on training set: 0.9816600000000001\n",
      "\n",
      "Validation loss: 0.07710571587085724\n",
      "Accuracy on validation set: 0.981\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.05454976484179497\n",
      "Accuracy on training set: 0.9816400000000001\n",
      "\n",
      "Validation loss: 0.08594533056020737\n",
      "Accuracy on validation set: 0.9782\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.0540129579603672\n",
      "Accuracy on training set: 0.9826600000000001\n",
      "\n",
      "Validation loss: 0.0796341747045517\n",
      "Accuracy on validation set: 0.9799\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.05244306102395058\n",
      "Accuracy on training set: 0.9827\n",
      "\n",
      "Validation loss: 0.07731535285711288\n",
      "Accuracy on validation set: 0.9798\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.05142315849661827\n",
      "Accuracy on training set: 0.9833800000000001\n",
      "\n",
      "Validation loss: 0.09112048149108887\n",
      "Accuracy on validation set: 0.9775\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.05245845392346382\n",
      "Accuracy on training set: 0.9832799999999999\n",
      "\n",
      "Validation loss: 0.08268149942159653\n",
      "Accuracy on validation set: 0.9792\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.04924488812685013\n",
      "Accuracy on training set: 0.98414\n",
      "\n",
      "Validation loss: 0.08532598614692688\n",
      "Accuracy on validation set: 0.9798\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.049184948205947876\n",
      "Accuracy on training set: 0.98406\n",
      "\n",
      "Validation loss: 0.08014293760061264\n",
      "Accuracy on validation set: 0.979\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.0477248914539814\n",
      "Accuracy on training set: 0.9842799999999999\n",
      "\n",
      "Validation loss: 0.0848161056637764\n",
      "Accuracy on validation set: 0.9794\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.05081237852573395\n",
      "Accuracy on training set: 0.9831400000000001\n",
      "\n",
      "Validation loss: 0.07722586393356323\n",
      "Accuracy on validation set: 0.9806\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.0460759736597538\n",
      "Accuracy on training set: 0.9845000000000002\n",
      "\n",
      "Validation loss: 0.08115456253290176\n",
      "Accuracy on validation set: 0.9788\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.08115456253290176\n",
      "Final accuracy on validation set: 0.9788\n",
      "\n",
      "\n",
      "##### MODEL: 3/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0.001, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': ReLU()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.39163294434547424\n",
      "Accuracy on training set: 0.8814000000000001\n",
      "\n",
      "Validation loss: 0.22455506026744843\n",
      "Accuracy on validation set: 0.9297\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.29895779490470886\n",
      "Accuracy on training set: 0.9096000000000002\n",
      "\n",
      "Validation loss: 0.2147107869386673\n",
      "Accuracy on validation set: 0.9358\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.2906527817249298\n",
      "Accuracy on training set: 0.9128400000000001\n",
      "\n",
      "Validation loss: 0.19503910839557648\n",
      "Accuracy on validation set: 0.9402\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.28933554887771606\n",
      "Accuracy on training set: 0.91262\n",
      "\n",
      "Validation loss: 0.1707601249217987\n",
      "Accuracy on validation set: 0.9497\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.2791796326637268\n",
      "Accuracy on training set: 0.91564\n",
      "\n",
      "Validation loss: 0.1738065630197525\n",
      "Accuracy on validation set: 0.9491\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.2841746211051941\n",
      "Accuracy on training set: 0.9146000000000002\n",
      "\n",
      "Validation loss: 0.1662871241569519\n",
      "Accuracy on validation set: 0.9506\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.2866663336753845\n",
      "Accuracy on training set: 0.9143800000000001\n",
      "\n",
      "Validation loss: 0.17749249935150146\n",
      "Accuracy on validation set: 0.9466\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.27846381068229675\n",
      "Accuracy on training set: 0.91652\n",
      "\n",
      "Validation loss: 0.1689218431711197\n",
      "Accuracy on validation set: 0.9503\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.27664560079574585\n",
      "Accuracy on training set: 0.9184000000000001\n",
      "\n",
      "Validation loss: 0.18248221278190613\n",
      "Accuracy on validation set: 0.9468\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.28503429889678955\n",
      "Accuracy on training set: 0.91552\n",
      "\n",
      "Validation loss: 0.19725295901298523\n",
      "Accuracy on validation set: 0.9411\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.28584587574005127\n",
      "Accuracy on training set: 0.91558\n",
      "\n",
      "Validation loss: 0.20590080320835114\n",
      "Accuracy on validation set: 0.9364\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.2803543210029602\n",
      "Accuracy on training set: 0.9169\n",
      "\n",
      "Validation loss: 0.16063809394836426\n",
      "Accuracy on validation set: 0.9507\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.2791048288345337\n",
      "Accuracy on training set: 0.91714\n",
      "\n",
      "Validation loss: 0.17596352100372314\n",
      "Accuracy on validation set: 0.9483\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.27891796827316284\n",
      "Accuracy on training set: 0.918\n",
      "\n",
      "Validation loss: 0.17585405707359314\n",
      "Accuracy on validation set: 0.9478\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.277736097574234\n",
      "Accuracy on training set: 0.9179400000000001\n",
      "\n",
      "Validation loss: 0.19014404714107513\n",
      "Accuracy on validation set: 0.9438\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.28026190400123596\n",
      "Accuracy on training set: 0.91798\n",
      "\n",
      "Validation loss: 0.18709781765937805\n",
      "Accuracy on validation set: 0.9436\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.28312939405441284\n",
      "Accuracy on training set: 0.9173200000000001\n",
      "\n",
      "Validation loss: 0.19071701169013977\n",
      "Accuracy on validation set: 0.9434\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.2814808785915375\n",
      "Accuracy on training set: 0.91642\n",
      "\n",
      "Validation loss: 0.1748233437538147\n",
      "Accuracy on validation set: 0.949\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.2825244665145874\n",
      "Accuracy on training set: 0.91662\n",
      "\n",
      "Validation loss: 0.18647819757461548\n",
      "Accuracy on validation set: 0.9456\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.2803402841091156\n",
      "Accuracy on training set: 0.91676\n",
      "\n",
      "Validation loss: 0.16965650022029877\n",
      "Accuracy on validation set: 0.95\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.28995710611343384\n",
      "Accuracy on training set: 0.9143600000000001\n",
      "\n",
      "Validation loss: 0.16567103564739227\n",
      "Accuracy on validation set: 0.9507\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.2843708395957947\n",
      "Accuracy on training set: 0.91598\n",
      "\n",
      "Validation loss: 0.17943397164344788\n",
      "Accuracy on validation set: 0.9461\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.28183192014694214\n",
      "Accuracy on training set: 0.91632\n",
      "\n",
      "Validation loss: 0.20073653757572174\n",
      "Accuracy on validation set: 0.9382\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.28308385610580444\n",
      "Accuracy on training set: 0.91612\n",
      "\n",
      "Validation loss: 0.16833990812301636\n",
      "Accuracy on validation set: 0.9493\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.2832626402378082\n",
      "Accuracy on training set: 0.9156599999999999\n",
      "\n",
      "Validation loss: 0.18213434517383575\n",
      "Accuracy on validation set: 0.9448\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.28184497356414795\n",
      "Accuracy on training set: 0.9164800000000001\n",
      "\n",
      "Validation loss: 0.18850019574165344\n",
      "Accuracy on validation set: 0.9438\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.2888318598270416\n",
      "Accuracy on training set: 0.91528\n",
      "\n",
      "Validation loss: 0.18784473836421967\n",
      "Accuracy on validation set: 0.9443\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.2836751937866211\n",
      "Accuracy on training set: 0.9177000000000001\n",
      "\n",
      "Validation loss: 0.20498405396938324\n",
      "Accuracy on validation set: 0.9438\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.28332385420799255\n",
      "Accuracy on training set: 0.91656\n",
      "\n",
      "Validation loss: 0.17816442251205444\n",
      "Accuracy on validation set: 0.9466\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.28520435094833374\n",
      "Accuracy on training set: 0.91546\n",
      "\n",
      "Validation loss: 0.18354426324367523\n",
      "Accuracy on validation set: 0.9479\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.18354426324367523\n",
      "Final accuracy on validation set: 0.9479\n",
      "\n",
      "\n",
      "##### MODEL: 4/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0.001, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 1.1403535604476929\n",
      "Accuracy on training set: 0.6550799999999999\n",
      "\n",
      "Validation loss: 0.5095440149307251\n",
      "Accuracy on validation set: 0.8713\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.568293571472168\n",
      "Accuracy on training set: 0.83848\n",
      "\n",
      "Validation loss: 0.39685729146003723\n",
      "Accuracy on validation set: 0.8947\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.4984515309333801\n",
      "Accuracy on training set: 0.85548\n",
      "\n",
      "Validation loss: 0.350286066532135\n",
      "Accuracy on validation set: 0.9044\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.470421701669693\n",
      "Accuracy on training set: 0.86334\n",
      "\n",
      "Validation loss: 0.3232482969760895\n",
      "Accuracy on validation set: 0.9103\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.453332781791687\n",
      "Accuracy on training set: 0.86652\n",
      "\n",
      "Validation loss: 0.30433565378189087\n",
      "Accuracy on validation set: 0.9157\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.4406699538230896\n",
      "Accuracy on training set: 0.87082\n",
      "\n",
      "Validation loss: 0.29154449701309204\n",
      "Accuracy on validation set: 0.9195\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.43096646666526794\n",
      "Accuracy on training set: 0.87348\n",
      "\n",
      "Validation loss: 0.28437110781669617\n",
      "Accuracy on validation set: 0.9202\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.4242886006832123\n",
      "Accuracy on training set: 0.8750800000000002\n",
      "\n",
      "Validation loss: 0.27895721793174744\n",
      "Accuracy on validation set: 0.9212\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.4190579950809479\n",
      "Accuracy on training set: 0.8774400000000001\n",
      "\n",
      "Validation loss: 0.272553414106369\n",
      "Accuracy on validation set: 0.9238\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.4120899736881256\n",
      "Accuracy on training set: 0.87892\n",
      "\n",
      "Validation loss: 0.2782091200351715\n",
      "Accuracy on validation set: 0.9227\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.4077518880367279\n",
      "Accuracy on training set: 0.8793\n",
      "\n",
      "Validation loss: 0.26640868186950684\n",
      "Accuracy on validation set: 0.9239\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.4047451317310333\n",
      "Accuracy on training set: 0.8817800000000001\n",
      "\n",
      "Validation loss: 0.26176562905311584\n",
      "Accuracy on validation set: 0.9245\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.4035169780254364\n",
      "Accuracy on training set: 0.8812600000000002\n",
      "\n",
      "Validation loss: 0.2594076097011566\n",
      "Accuracy on validation set: 0.9276\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.40238332748413086\n",
      "Accuracy on training set: 0.88154\n",
      "\n",
      "Validation loss: 0.2603811025619507\n",
      "Accuracy on validation set: 0.9269\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.39846691489219666\n",
      "Accuracy on training set: 0.8835200000000002\n",
      "\n",
      "Validation loss: 0.2593446671962738\n",
      "Accuracy on validation set: 0.9261\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.3966219425201416\n",
      "Accuracy on training set: 0.88392\n",
      "\n",
      "Validation loss: 0.2528816759586334\n",
      "Accuracy on validation set: 0.9299\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.3961028754711151\n",
      "Accuracy on training set: 0.8827400000000001\n",
      "\n",
      "Validation loss: 0.2599465250968933\n",
      "Accuracy on validation set: 0.9267\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.3983705937862396\n",
      "Accuracy on training set: 0.8823\n",
      "\n",
      "Validation loss: 0.2559719979763031\n",
      "Accuracy on validation set: 0.9271\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.39607349038124084\n",
      "Accuracy on training set: 0.8833\n",
      "\n",
      "Validation loss: 0.25751638412475586\n",
      "Accuracy on validation set: 0.9256\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.397211492061615\n",
      "Accuracy on training set: 0.88374\n",
      "\n",
      "Validation loss: 0.25682148337364197\n",
      "Accuracy on validation set: 0.9288\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.39178043603897095\n",
      "Accuracy on training set: 0.8849600000000001\n",
      "\n",
      "Validation loss: 0.2513790726661682\n",
      "Accuracy on validation set: 0.9279\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.39318299293518066\n",
      "Accuracy on training set: 0.88392\n",
      "\n",
      "Validation loss: 0.2563290596008301\n",
      "Accuracy on validation set: 0.9266\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.3924928903579712\n",
      "Accuracy on training set: 0.88374\n",
      "\n",
      "Validation loss: 0.25431767106056213\n",
      "Accuracy on validation set: 0.9297\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.3937908113002777\n",
      "Accuracy on training set: 0.88398\n",
      "\n",
      "Validation loss: 0.2525164783000946\n",
      "Accuracy on validation set: 0.9282\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.3916083872318268\n",
      "Accuracy on training set: 0.8846200000000001\n",
      "\n",
      "Validation loss: 0.2550971806049347\n",
      "Accuracy on validation set: 0.928\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.3921172618865967\n",
      "Accuracy on training set: 0.8847600000000001\n",
      "\n",
      "Validation loss: 0.25603529810905457\n",
      "Accuracy on validation set: 0.9278\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.3960578143596649\n",
      "Accuracy on training set: 0.88386\n",
      "\n",
      "Validation loss: 0.2550334334373474\n",
      "Accuracy on validation set: 0.9278\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.39368414878845215\n",
      "Accuracy on training set: 0.88478\n",
      "\n",
      "Validation loss: 0.2563450038433075\n",
      "Accuracy on validation set: 0.9291\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.39252573251724243\n",
      "Accuracy on training set: 0.8848400000000001\n",
      "\n",
      "Validation loss: 0.25533443689346313\n",
      "Accuracy on validation set: 0.928\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.3901962339878082\n",
      "Accuracy on training set: 0.88448\n",
      "\n",
      "Validation loss: 0.24870756268501282\n",
      "Accuracy on validation set: 0.9313\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.24870756268501282\n",
      "Final accuracy on validation set: 0.9313\n",
      "\n",
      "\n",
      "##### MODEL: 5/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0.0001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0, 'Act_func': ReLU()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.3293333351612091\n",
      "Accuracy on training set: 0.90406\n",
      "\n",
      "Validation loss: 0.1980474889278412\n",
      "Accuracy on validation set: 0.9412\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.16198764741420746\n",
      "Accuracy on training set: 0.9527\n",
      "\n",
      "Validation loss: 0.1437976062297821\n",
      "Accuracy on validation set: 0.9581\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.11556734889745712\n",
      "Accuracy on training set: 0.9651000000000002\n",
      "\n",
      "Validation loss: 0.15260745584964752\n",
      "Accuracy on validation set: 0.9545\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.09136666357517242\n",
      "Accuracy on training set: 0.97282\n",
      "\n",
      "Validation loss: 0.11281249672174454\n",
      "Accuracy on validation set: 0.9655\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.07557731866836548\n",
      "Accuracy on training set: 0.9764400000000001\n",
      "\n",
      "Validation loss: 0.0943804681301117\n",
      "Accuracy on validation set: 0.9723\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.06404687464237213\n",
      "Accuracy on training set: 0.98004\n",
      "\n",
      "Validation loss: 0.09173267334699631\n",
      "Accuracy on validation set: 0.9715\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.05456465110182762\n",
      "Accuracy on training set: 0.98246\n",
      "\n",
      "Validation loss: 0.09320887923240662\n",
      "Accuracy on validation set: 0.9747\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.04839186742901802\n",
      "Accuracy on training set: 0.98434\n",
      "\n",
      "Validation loss: 0.10125808417797089\n",
      "Accuracy on validation set: 0.9706\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.04249832034111023\n",
      "Accuracy on training set: 0.9862600000000001\n",
      "\n",
      "Validation loss: 0.09202925115823746\n",
      "Accuracy on validation set: 0.9743\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.03823001682758331\n",
      "Accuracy on training set: 0.9878200000000001\n",
      "\n",
      "Validation loss: 0.09743773937225342\n",
      "Accuracy on validation set: 0.9718\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.03410894051194191\n",
      "Accuracy on training set: 0.9888800000000001\n",
      "\n",
      "Validation loss: 0.08234534412622452\n",
      "Accuracy on validation set: 0.9782\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.03174687922000885\n",
      "Accuracy on training set: 0.9904800000000001\n",
      "\n",
      "Validation loss: 0.08816985785961151\n",
      "Accuracy on validation set: 0.9768\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.028685301542282104\n",
      "Accuracy on training set: 0.9911400000000001\n",
      "\n",
      "Validation loss: 0.09191087633371353\n",
      "Accuracy on validation set: 0.9749\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.026172557845711708\n",
      "Accuracy on training set: 0.9915600000000001\n",
      "\n",
      "Validation loss: 0.08370660990476608\n",
      "Accuracy on validation set: 0.9764\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.02464447170495987\n",
      "Accuracy on training set: 0.9923000000000002\n",
      "\n",
      "Validation loss: 0.09696450084447861\n",
      "Accuracy on validation set: 0.9735\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.022465616464614868\n",
      "Accuracy on training set: 0.9929600000000001\n",
      "\n",
      "Validation loss: 0.0991387665271759\n",
      "Accuracy on validation set: 0.9744\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.022325092926621437\n",
      "Accuracy on training set: 0.9928400000000001\n",
      "\n",
      "Validation loss: 0.09969443082809448\n",
      "Accuracy on validation set: 0.9724\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.02095486782491207\n",
      "Accuracy on training set: 0.9932000000000001\n",
      "\n",
      "Validation loss: 0.10468779504299164\n",
      "Accuracy on validation set: 0.9755\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.019408175721764565\n",
      "Accuracy on training set: 0.9938400000000002\n",
      "\n",
      "Validation loss: 0.09290362894535065\n",
      "Accuracy on validation set: 0.9756\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.019023574888706207\n",
      "Accuracy on training set: 0.9938600000000001\n",
      "\n",
      "Validation loss: 0.10050293803215027\n",
      "Accuracy on validation set: 0.9749\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.017996888607740402\n",
      "Accuracy on training set: 0.9941800000000001\n",
      "\n",
      "Validation loss: 0.10710790753364563\n",
      "Accuracy on validation set: 0.9714\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.017431238666176796\n",
      "Accuracy on training set: 0.9945400000000001\n",
      "\n",
      "Validation loss: 0.09498526155948639\n",
      "Accuracy on validation set: 0.9778\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.018085354939103127\n",
      "Accuracy on training set: 0.99398\n",
      "\n",
      "Validation loss: 0.10087916254997253\n",
      "Accuracy on validation set: 0.9754\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.01678699068725109\n",
      "Accuracy on training set: 0.99468\n",
      "\n",
      "Validation loss: 0.10466810315847397\n",
      "Accuracy on validation set: 0.9741\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.015493277460336685\n",
      "Accuracy on training set: 0.99526\n",
      "\n",
      "Validation loss: 0.0975508838891983\n",
      "Accuracy on validation set: 0.9752\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.01580185815691948\n",
      "Accuracy on training set: 0.9951200000000001\n",
      "\n",
      "Validation loss: 0.09577637910842896\n",
      "Accuracy on validation set: 0.9765\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.016175944358110428\n",
      "Accuracy on training set: 0.9947600000000001\n",
      "\n",
      "Validation loss: 0.10099945962429047\n",
      "Accuracy on validation set: 0.9754\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.014489827677607536\n",
      "Accuracy on training set: 0.9950600000000001\n",
      "\n",
      "Validation loss: 0.09203935414552689\n",
      "Accuracy on validation set: 0.9781\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.014770173467695713\n",
      "Accuracy on training set: 0.99522\n",
      "\n",
      "Validation loss: 0.09026679396629333\n",
      "Accuracy on validation set: 0.9781\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.014565047807991505\n",
      "Accuracy on training set: 0.99522\n",
      "\n",
      "Validation loss: 0.09553178399801254\n",
      "Accuracy on validation set: 0.9773\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.09553178399801254\n",
      "Final accuracy on validation set: 0.9773\n",
      "\n",
      "\n",
      "##### MODEL: 6/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0.001, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0, 'Act_func': ReLU()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.27715903520584106\n",
      "Accuracy on training set: 0.914\n",
      "\n",
      "Validation loss: 0.19258631765842438\n",
      "Accuracy on validation set: 0.9437\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.17273592948913574\n",
      "Accuracy on training set: 0.9479\n",
      "\n",
      "Validation loss: 0.15607231855392456\n",
      "Accuracy on validation set: 0.9501\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.15567931532859802\n",
      "Accuracy on training set: 0.95284\n",
      "\n",
      "Validation loss: 0.17417411506175995\n",
      "Accuracy on validation set: 0.9473\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.15238043665885925\n",
      "Accuracy on training set: 0.95334\n",
      "\n",
      "Validation loss: 0.16731958091259003\n",
      "Accuracy on validation set: 0.9492\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.14550115168094635\n",
      "Accuracy on training set: 0.95486\n",
      "\n",
      "Validation loss: 0.12899860739707947\n",
      "Accuracy on validation set: 0.9617\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.14029531180858612\n",
      "Accuracy on training set: 0.9550599999999999\n",
      "\n",
      "Validation loss: 0.14723604917526245\n",
      "Accuracy on validation set: 0.9573\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.14313317835330963\n",
      "Accuracy on training set: 0.95604\n",
      "\n",
      "Validation loss: 0.15238314867019653\n",
      "Accuracy on validation set: 0.9552\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.13856634497642517\n",
      "Accuracy on training set: 0.95782\n",
      "\n",
      "Validation loss: 0.15297947824001312\n",
      "Accuracy on validation set: 0.9544\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.13938580453395844\n",
      "Accuracy on training set: 0.9579\n",
      "\n",
      "Validation loss: 0.144853413105011\n",
      "Accuracy on validation set: 0.9548\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.1359080821275711\n",
      "Accuracy on training set: 0.95806\n",
      "\n",
      "Validation loss: 0.16219617426395416\n",
      "Accuracy on validation set: 0.9503\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.13869789242744446\n",
      "Accuracy on training set: 0.95704\n",
      "\n",
      "Validation loss: 0.1521124541759491\n",
      "Accuracy on validation set: 0.9569\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.13584430515766144\n",
      "Accuracy on training set: 0.9584600000000001\n",
      "\n",
      "Validation loss: 0.15409739315509796\n",
      "Accuracy on validation set: 0.951\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.13667504489421844\n",
      "Accuracy on training set: 0.9589200000000001\n",
      "\n",
      "Validation loss: 0.1385297179222107\n",
      "Accuracy on validation set: 0.9594\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.1341385394334793\n",
      "Accuracy on training set: 0.95894\n",
      "\n",
      "Validation loss: 0.13099874556064606\n",
      "Accuracy on validation set: 0.9614\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.13283541798591614\n",
      "Accuracy on training set: 0.95824\n",
      "\n",
      "Validation loss: 0.1409226953983307\n",
      "Accuracy on validation set: 0.9588\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.1323423981666565\n",
      "Accuracy on training set: 0.9594\n",
      "\n",
      "Validation loss: 0.14916734397411346\n",
      "Accuracy on validation set: 0.9543\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.1328352391719818\n",
      "Accuracy on training set: 0.95998\n",
      "\n",
      "Validation loss: 0.1494101583957672\n",
      "Accuracy on validation set: 0.9539\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.13419359922409058\n",
      "Accuracy on training set: 0.9588000000000001\n",
      "\n",
      "Validation loss: 0.1550990790128708\n",
      "Accuracy on validation set: 0.9525\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.13088293373584747\n",
      "Accuracy on training set: 0.9588199999999999\n",
      "\n",
      "Validation loss: 0.13055332005023956\n",
      "Accuracy on validation set: 0.9617\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.13244231045246124\n",
      "Accuracy on training set: 0.95998\n",
      "\n",
      "Validation loss: 0.15590016543865204\n",
      "Accuracy on validation set: 0.9549\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.13544735312461853\n",
      "Accuracy on training set: 0.9586399999999999\n",
      "\n",
      "Validation loss: 0.14507274329662323\n",
      "Accuracy on validation set: 0.9544\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.1308422088623047\n",
      "Accuracy on training set: 0.9603400000000001\n",
      "\n",
      "Validation loss: 0.13081978261470795\n",
      "Accuracy on validation set: 0.9601\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.13252028822898865\n",
      "Accuracy on training set: 0.95848\n",
      "\n",
      "Validation loss: 0.14519929885864258\n",
      "Accuracy on validation set: 0.9546\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.13247542083263397\n",
      "Accuracy on training set: 0.9586\n",
      "\n",
      "Validation loss: 0.13879692554473877\n",
      "Accuracy on validation set: 0.9574\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.1302696019411087\n",
      "Accuracy on training set: 0.9605199999999999\n",
      "\n",
      "Validation loss: 0.1458265632390976\n",
      "Accuracy on validation set: 0.9542\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.13281066715717316\n",
      "Accuracy on training set: 0.9598\n",
      "\n",
      "Validation loss: 0.1344122737646103\n",
      "Accuracy on validation set: 0.9611\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.13275174796581268\n",
      "Accuracy on training set: 0.95882\n",
      "\n",
      "Validation loss: 0.15178845822811127\n",
      "Accuracy on validation set: 0.9557\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.13045485317707062\n",
      "Accuracy on training set: 0.9598399999999999\n",
      "\n",
      "Validation loss: 0.12995342910289764\n",
      "Accuracy on validation set: 0.9608\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.13097302615642548\n",
      "Accuracy on training set: 0.95994\n",
      "\n",
      "Validation loss: 0.14323678612709045\n",
      "Accuracy on validation set: 0.9571\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.13334891200065613\n",
      "Accuracy on training set: 0.95978\n",
      "\n",
      "Validation loss: 0.12054502964019775\n",
      "Accuracy on validation set: 0.9632\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.12054502964019775\n",
      "Final accuracy on validation set: 0.9632\n",
      "\n",
      "\n",
      "##### MODEL: 7/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.6182458400726318\n",
      "Accuracy on training set: 0.8271000000000002\n",
      "\n",
      "Validation loss: 0.26105940341949463\n",
      "Accuracy on validation set: 0.9244\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.21490833163261414\n",
      "Accuracy on training set: 0.9365\n",
      "\n",
      "Validation loss: 0.19140444695949554\n",
      "Accuracy on validation set: 0.9444\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.1535130888223648\n",
      "Accuracy on training set: 0.9544600000000001\n",
      "\n",
      "Validation loss: 0.154344841837883\n",
      "Accuracy on validation set: 0.9545\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.11872559040784836\n",
      "Accuracy on training set: 0.9649200000000001\n",
      "\n",
      "Validation loss: 0.13054057955741882\n",
      "Accuracy on validation set: 0.96\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.09492480754852295\n",
      "Accuracy on training set: 0.9726\n",
      "\n",
      "Validation loss: 0.11586976051330566\n",
      "Accuracy on validation set: 0.9645\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.07730630785226822\n",
      "Accuracy on training set: 0.97748\n",
      "\n",
      "Validation loss: 0.10839015245437622\n",
      "Accuracy on validation set: 0.9665\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.0627724751830101\n",
      "Accuracy on training set: 0.9815200000000001\n",
      "\n",
      "Validation loss: 0.10190340876579285\n",
      "Accuracy on validation set: 0.9705\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.050640836358070374\n",
      "Accuracy on training set: 0.9851400000000001\n",
      "\n",
      "Validation loss: 0.09264359623193741\n",
      "Accuracy on validation set: 0.9722\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.041463784873485565\n",
      "Accuracy on training set: 0.98826\n",
      "\n",
      "Validation loss: 0.09577815234661102\n",
      "Accuracy on validation set: 0.9717\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.03396032750606537\n",
      "Accuracy on training set: 0.9901800000000001\n",
      "\n",
      "Validation loss: 0.09731611609458923\n",
      "Accuracy on validation set: 0.9714\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.027878576889634132\n",
      "Accuracy on training set: 0.9923400000000001\n",
      "\n",
      "Validation loss: 0.0916852280497551\n",
      "Accuracy on validation set: 0.9731\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.022662624716758728\n",
      "Accuracy on training set: 0.9941400000000001\n",
      "\n",
      "Validation loss: 0.0900898277759552\n",
      "Accuracy on validation set: 0.9741\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.017869189381599426\n",
      "Accuracy on training set: 0.9953200000000001\n",
      "\n",
      "Validation loss: 0.1048923209309578\n",
      "Accuracy on validation set: 0.9723\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.01431665662676096\n",
      "Accuracy on training set: 0.9963000000000001\n",
      "\n",
      "Validation loss: 0.09305077791213989\n",
      "Accuracy on validation set: 0.9749\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.012161819264292717\n",
      "Accuracy on training set: 0.9970600000000001\n",
      "\n",
      "Validation loss: 0.10151289403438568\n",
      "Accuracy on validation set: 0.9729\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.008571929298341274\n",
      "Accuracy on training set: 0.99834\n",
      "\n",
      "Validation loss: 0.10032419860363007\n",
      "Accuracy on validation set: 0.9752\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.007166683208197355\n",
      "Accuracy on training set: 0.99842\n",
      "\n",
      "Validation loss: 0.10316862910985947\n",
      "Accuracy on validation set: 0.9742\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.007594658061861992\n",
      "Accuracy on training set: 0.9981\n",
      "\n",
      "Validation loss: 0.10680513828992844\n",
      "Accuracy on validation set: 0.9744\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.005386128090322018\n",
      "Accuracy on training set: 0.99888\n",
      "\n",
      "Validation loss: 0.11105197668075562\n",
      "Accuracy on validation set: 0.9736\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.003970564343035221\n",
      "Accuracy on training set: 0.99924\n",
      "\n",
      "Validation loss: 0.11737404763698578\n",
      "Accuracy on validation set: 0.9719\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.005566494073718786\n",
      "Accuracy on training set: 0.99852\n",
      "\n",
      "Validation loss: 0.12129172682762146\n",
      "Accuracy on validation set: 0.9734\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.0026712568942457438\n",
      "Accuracy on training set: 0.99956\n",
      "\n",
      "Validation loss: 0.11333620548248291\n",
      "Accuracy on validation set: 0.9761\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.0013577139470726252\n",
      "Accuracy on training set: 0.99986\n",
      "\n",
      "Validation loss: 0.11615204811096191\n",
      "Accuracy on validation set: 0.9758\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.00638657808303833\n",
      "Accuracy on training set: 0.9981200000000001\n",
      "\n",
      "Validation loss: 0.1348489373922348\n",
      "Accuracy on validation set: 0.9739\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.0018929579528048635\n",
      "Accuracy on training set: 0.99968\n",
      "\n",
      "Validation loss: 0.12039898335933685\n",
      "Accuracy on validation set: 0.9754\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.0006179236224852502\n",
      "Accuracy on training set: 0.9999600000000001\n",
      "\n",
      "Validation loss: 0.1304769665002823\n",
      "Accuracy on validation set: 0.9748\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.005700885318219662\n",
      "Accuracy on training set: 0.9981400000000001\n",
      "\n",
      "Validation loss: 0.1336309164762497\n",
      "Accuracy on validation set: 0.9737\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.0022121795918792486\n",
      "Accuracy on training set: 0.99952\n",
      "\n",
      "Validation loss: 0.1293295919895172\n",
      "Accuracy on validation set: 0.9747\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.0013432935811579227\n",
      "Accuracy on training set: 0.99976\n",
      "\n",
      "Validation loss: 0.1290166825056076\n",
      "Accuracy on validation set: 0.9754\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.0004319429863244295\n",
      "Accuracy on training set: 1.0\n",
      "\n",
      "Validation loss: 0.13065339624881744\n",
      "Accuracy on validation set: 0.9746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.13065339624881744\n",
      "Final accuracy on validation set: 0.9746\n",
      "\n",
      "\n",
      "##### MODEL: 8/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0.0001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.8713589310646057\n",
      "Accuracy on training set: 0.74794\n",
      "\n",
      "Validation loss: 0.39103490114212036\n",
      "Accuracy on validation set: 0.8905\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.4363763630390167\n",
      "Accuracy on training set: 0.87492\n",
      "\n",
      "Validation loss: 0.29433301091194153\n",
      "Accuracy on validation set: 0.9145\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.3633882701396942\n",
      "Accuracy on training set: 0.89408\n",
      "\n",
      "Validation loss: 0.24757327139377594\n",
      "Accuracy on validation set: 0.9267\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.3249959647655487\n",
      "Accuracy on training set: 0.9057200000000001\n",
      "\n",
      "Validation loss: 0.2169823795557022\n",
      "Accuracy on validation set: 0.9344\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.30164122581481934\n",
      "Accuracy on training set: 0.9106600000000001\n",
      "\n",
      "Validation loss: 0.19766871631145477\n",
      "Accuracy on validation set: 0.9402\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.281311571598053\n",
      "Accuracy on training set: 0.9165399999999999\n",
      "\n",
      "Validation loss: 0.18127328157424927\n",
      "Accuracy on validation set: 0.9454\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.2685345709323883\n",
      "Accuracy on training set: 0.92126\n",
      "\n",
      "Validation loss: 0.17338140308856964\n",
      "Accuracy on validation set: 0.9487\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.25768834352493286\n",
      "Accuracy on training set: 0.9227799999999999\n",
      "\n",
      "Validation loss: 0.1645732969045639\n",
      "Accuracy on validation set: 0.9492\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.24750380218029022\n",
      "Accuracy on training set: 0.92604\n",
      "\n",
      "Validation loss: 0.15904133021831512\n",
      "Accuracy on validation set: 0.9524\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.2407991886138916\n",
      "Accuracy on training set: 0.9286\n",
      "\n",
      "Validation loss: 0.15530996024608612\n",
      "Accuracy on validation set: 0.9511\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.23381224274635315\n",
      "Accuracy on training set: 0.9301800000000001\n",
      "\n",
      "Validation loss: 0.14693796634674072\n",
      "Accuracy on validation set: 0.9536\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.22615857422351837\n",
      "Accuracy on training set: 0.9322\n",
      "\n",
      "Validation loss: 0.14489196240901947\n",
      "Accuracy on validation set: 0.9561\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.22048527002334595\n",
      "Accuracy on training set: 0.9337799999999999\n",
      "\n",
      "Validation loss: 0.14123448729515076\n",
      "Accuracy on validation set: 0.9573\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.22156375646591187\n",
      "Accuracy on training set: 0.93298\n",
      "\n",
      "Validation loss: 0.14005303382873535\n",
      "Accuracy on validation set: 0.9567\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.21604116261005402\n",
      "Accuracy on training set: 0.935\n",
      "\n",
      "Validation loss: 0.13571476936340332\n",
      "Accuracy on validation set: 0.9589\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.21373093128204346\n",
      "Accuracy on training set: 0.93616\n",
      "\n",
      "Validation loss: 0.1335686594247818\n",
      "Accuracy on validation set: 0.9588\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.20855191349983215\n",
      "Accuracy on training set: 0.9371600000000001\n",
      "\n",
      "Validation loss: 0.13331764936447144\n",
      "Accuracy on validation set: 0.9594\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.20967626571655273\n",
      "Accuracy on training set: 0.9361600000000001\n",
      "\n",
      "Validation loss: 0.12919984757900238\n",
      "Accuracy on validation set: 0.9596\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.204204723238945\n",
      "Accuracy on training set: 0.9382\n",
      "\n",
      "Validation loss: 0.1307215839624405\n",
      "Accuracy on validation set: 0.9609\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.20586486160755157\n",
      "Accuracy on training set: 0.93828\n",
      "\n",
      "Validation loss: 0.12824061512947083\n",
      "Accuracy on validation set: 0.9602\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.20183363556861877\n",
      "Accuracy on training set: 0.93902\n",
      "\n",
      "Validation loss: 0.12798704206943512\n",
      "Accuracy on validation set: 0.9604\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.19874770939350128\n",
      "Accuracy on training set: 0.941\n",
      "\n",
      "Validation loss: 0.12661688029766083\n",
      "Accuracy on validation set: 0.9608\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.19784677028656006\n",
      "Accuracy on training set: 0.9395600000000001\n",
      "\n",
      "Validation loss: 0.12795716524124146\n",
      "Accuracy on validation set: 0.9613\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.20132766664028168\n",
      "Accuracy on training set: 0.93924\n",
      "\n",
      "Validation loss: 0.12289564311504364\n",
      "Accuracy on validation set: 0.963\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.1960410475730896\n",
      "Accuracy on training set: 0.9403400000000001\n",
      "\n",
      "Validation loss: 0.12091251462697983\n",
      "Accuracy on validation set: 0.9634\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.19679751992225647\n",
      "Accuracy on training set: 0.94088\n",
      "\n",
      "Validation loss: 0.1233668327331543\n",
      "Accuracy on validation set: 0.9635\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.1983116865158081\n",
      "Accuracy on training set: 0.93998\n",
      "\n",
      "Validation loss: 0.12136544287204742\n",
      "Accuracy on validation set: 0.9639\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.19326037168502808\n",
      "Accuracy on training set: 0.94134\n",
      "\n",
      "Validation loss: 0.11817480623722076\n",
      "Accuracy on validation set: 0.9636\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.1937682330608368\n",
      "Accuracy on training set: 0.94098\n",
      "\n",
      "Validation loss: 0.11834100633859634\n",
      "Accuracy on validation set: 0.9651\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.19063140451908112\n",
      "Accuracy on training set: 0.94232\n",
      "\n",
      "Validation loss: 0.1166047751903534\n",
      "Accuracy on validation set: 0.9644\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.1166047751903534\n",
      "Final accuracy on validation set: 0.9644\n",
      "\n",
      "\n",
      "##### MODEL: 9/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0.001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.44658443331718445\n",
      "Accuracy on training set: 0.8664400000000001\n",
      "\n",
      "Validation loss: 0.27855345606803894\n",
      "Accuracy on validation set: 0.9204\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.2795421779155731\n",
      "Accuracy on training set: 0.92\n",
      "\n",
      "Validation loss: 0.24759477376937866\n",
      "Accuracy on validation set: 0.9345\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.26036614179611206\n",
      "Accuracy on training set: 0.9262400000000001\n",
      "\n",
      "Validation loss: 0.2812636196613312\n",
      "Accuracy on validation set: 0.9209\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.2514139413833618\n",
      "Accuracy on training set: 0.92802\n",
      "\n",
      "Validation loss: 0.21944841742515564\n",
      "Accuracy on validation set: 0.9402\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.24460037052631378\n",
      "Accuracy on training set: 0.9311\n",
      "\n",
      "Validation loss: 0.2815088927745819\n",
      "Accuracy on validation set: 0.9214\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.2453342229127884\n",
      "Accuracy on training set: 0.93026\n",
      "\n",
      "Validation loss: 0.21817778050899506\n",
      "Accuracy on validation set: 0.94\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.24350249767303467\n",
      "Accuracy on training set: 0.93098\n",
      "\n",
      "Validation loss: 0.2193361073732376\n",
      "Accuracy on validation set: 0.9389\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.23835842311382294\n",
      "Accuracy on training set: 0.93302\n",
      "\n",
      "Validation loss: 0.22881010174751282\n",
      "Accuracy on validation set: 0.939\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.23905660212039948\n",
      "Accuracy on training set: 0.9329200000000001\n",
      "\n",
      "Validation loss: 0.2299739569425583\n",
      "Accuracy on validation set: 0.9336\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.23801931738853455\n",
      "Accuracy on training set: 0.9329000000000001\n",
      "\n",
      "Validation loss: 0.2796871066093445\n",
      "Accuracy on validation set: 0.9171\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.2350432574748993\n",
      "Accuracy on training set: 0.9333400000000001\n",
      "\n",
      "Validation loss: 0.2636849284172058\n",
      "Accuracy on validation set: 0.9216\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.2353786677122116\n",
      "Accuracy on training set: 0.93402\n",
      "\n",
      "Validation loss: 0.2482200264930725\n",
      "Accuracy on validation set: 0.9274\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.23469391465187073\n",
      "Accuracy on training set: 0.9335999999999999\n",
      "\n",
      "Validation loss: 0.2552957534790039\n",
      "Accuracy on validation set: 0.9249\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.2351495623588562\n",
      "Accuracy on training set: 0.9336199999999999\n",
      "\n",
      "Validation loss: 0.22283215820789337\n",
      "Accuracy on validation set: 0.9418\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.23252440989017487\n",
      "Accuracy on training set: 0.93454\n",
      "\n",
      "Validation loss: 0.24201162159442902\n",
      "Accuracy on validation set: 0.9306\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.23275567591190338\n",
      "Accuracy on training set: 0.9342999999999999\n",
      "\n",
      "Validation loss: 0.24228784441947937\n",
      "Accuracy on validation set: 0.9285\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.2331208884716034\n",
      "Accuracy on training set: 0.93496\n",
      "\n",
      "Validation loss: 0.22564001381397247\n",
      "Accuracy on validation set: 0.9385\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.2341519296169281\n",
      "Accuracy on training set: 0.9330799999999999\n",
      "\n",
      "Validation loss: 0.253633052110672\n",
      "Accuracy on validation set: 0.9259\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.23234155774116516\n",
      "Accuracy on training set: 0.93462\n",
      "\n",
      "Validation loss: 0.22749371826648712\n",
      "Accuracy on validation set: 0.9376\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.2340361475944519\n",
      "Accuracy on training set: 0.93382\n",
      "\n",
      "Validation loss: 0.2402028739452362\n",
      "Accuracy on validation set: 0.9323\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.23165741562843323\n",
      "Accuracy on training set: 0.93542\n",
      "\n",
      "Validation loss: 0.21432796120643616\n",
      "Accuracy on validation set: 0.9417\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.23268374800682068\n",
      "Accuracy on training set: 0.93518\n",
      "\n",
      "Validation loss: 0.2209136039018631\n",
      "Accuracy on validation set: 0.9428\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.23255330324172974\n",
      "Accuracy on training set: 0.93448\n",
      "\n",
      "Validation loss: 0.28282251954078674\n",
      "Accuracy on validation set: 0.9171\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.2325223684310913\n",
      "Accuracy on training set: 0.9340799999999999\n",
      "\n",
      "Validation loss: 0.25793328881263733\n",
      "Accuracy on validation set: 0.9253\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.2329104244709015\n",
      "Accuracy on training set: 0.9357\n",
      "\n",
      "Validation loss: 0.23411862552165985\n",
      "Accuracy on validation set: 0.933\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.23082514107227325\n",
      "Accuracy on training set: 0.9343199999999999\n",
      "\n",
      "Validation loss: 0.229056715965271\n",
      "Accuracy on validation set: 0.9386\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.23179268836975098\n",
      "Accuracy on training set: 0.93524\n",
      "\n",
      "Validation loss: 0.22474153339862823\n",
      "Accuracy on validation set: 0.9404\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.23243527114391327\n",
      "Accuracy on training set: 0.93484\n",
      "\n",
      "Validation loss: 0.2214135229587555\n",
      "Accuracy on validation set: 0.9367\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.2328178733587265\n",
      "Accuracy on training set: 0.9343400000000002\n",
      "\n",
      "Validation loss: 0.24035683274269104\n",
      "Accuracy on validation set: 0.9322\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.23173928260803223\n",
      "Accuracy on training set: 0.93548\n",
      "\n",
      "Validation loss: 0.22071456909179688\n",
      "Accuracy on validation set: 0.9387\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.22071456909179688\n",
      "Final accuracy on validation set: 0.9387\n",
      "\n",
      "\n",
      "##### MODEL: 10/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0.001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': ReLU()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.3735230267047882\n",
      "Accuracy on training set: 0.88712\n",
      "\n",
      "Validation loss: 0.1769443303346634\n",
      "Accuracy on validation set: 0.9475\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.21083401143550873\n",
      "Accuracy on training set: 0.9379\n",
      "\n",
      "Validation loss: 0.13844552636146545\n",
      "Accuracy on validation set: 0.9563\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.17550478875637054\n",
      "Accuracy on training set: 0.9476000000000001\n",
      "\n",
      "Validation loss: 0.14516566693782806\n",
      "Accuracy on validation set: 0.9557\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.16030651330947876\n",
      "Accuracy on training set: 0.95178\n",
      "\n",
      "Validation loss: 0.11166384071111679\n",
      "Accuracy on validation set: 0.9657\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.14990828931331635\n",
      "Accuracy on training set: 0.9554600000000001\n",
      "\n",
      "Validation loss: 0.09998029470443726\n",
      "Accuracy on validation set: 0.9706\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.14520564675331116\n",
      "Accuracy on training set: 0.95594\n",
      "\n",
      "Validation loss: 0.10159878432750702\n",
      "Accuracy on validation set: 0.9689\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.13871154189109802\n",
      "Accuracy on training set: 0.95878\n",
      "\n",
      "Validation loss: 0.10016725957393646\n",
      "Accuracy on validation set: 0.9705\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.13671456277370453\n",
      "Accuracy on training set: 0.95972\n",
      "\n",
      "Validation loss: 0.10166844725608826\n",
      "Accuracy on validation set: 0.9704\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.13733646273612976\n",
      "Accuracy on training set: 0.9584400000000001\n",
      "\n",
      "Validation loss: 0.09682021290063858\n",
      "Accuracy on validation set: 0.971\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.13336417078971863\n",
      "Accuracy on training set: 0.9594199999999999\n",
      "\n",
      "Validation loss: 0.09186868369579315\n",
      "Accuracy on validation set: 0.9717\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.13024954497814178\n",
      "Accuracy on training set: 0.96146\n",
      "\n",
      "Validation loss: 0.09682728350162506\n",
      "Accuracy on validation set: 0.9712\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.1315997838973999\n",
      "Accuracy on training set: 0.9606600000000001\n",
      "\n",
      "Validation loss: 0.09722453355789185\n",
      "Accuracy on validation set: 0.9701\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.12864351272583008\n",
      "Accuracy on training set: 0.9613600000000001\n",
      "\n",
      "Validation loss: 0.09883897751569748\n",
      "Accuracy on validation set: 0.9704\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.12878423929214478\n",
      "Accuracy on training set: 0.96064\n",
      "\n",
      "Validation loss: 0.09841553121805191\n",
      "Accuracy on validation set: 0.9707\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.126946359872818\n",
      "Accuracy on training set: 0.9618\n",
      "\n",
      "Validation loss: 0.09431960433721542\n",
      "Accuracy on validation set: 0.9717\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.12755268812179565\n",
      "Accuracy on training set: 0.96148\n",
      "\n",
      "Validation loss: 0.09199108928442001\n",
      "Accuracy on validation set: 0.972\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.12565074861049652\n",
      "Accuracy on training set: 0.9625\n",
      "\n",
      "Validation loss: 0.09691645205020905\n",
      "Accuracy on validation set: 0.9717\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.12339355796575546\n",
      "Accuracy on training set: 0.96296\n",
      "\n",
      "Validation loss: 0.09942109137773514\n",
      "Accuracy on validation set: 0.971\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.1271602213382721\n",
      "Accuracy on training set: 0.9618800000000001\n",
      "\n",
      "Validation loss: 0.09385766088962555\n",
      "Accuracy on validation set: 0.9716\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.12433882057666779\n",
      "Accuracy on training set: 0.9623\n",
      "\n",
      "Validation loss: 0.09525762498378754\n",
      "Accuracy on validation set: 0.97\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.12514357268810272\n",
      "Accuracy on training set: 0.96228\n",
      "\n",
      "Validation loss: 0.09358473867177963\n",
      "Accuracy on validation set: 0.9714\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.12457237392663956\n",
      "Accuracy on training set: 0.9626800000000001\n",
      "\n",
      "Validation loss: 0.0921168252825737\n",
      "Accuracy on validation set: 0.9723\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.12171963602304459\n",
      "Accuracy on training set: 0.9634000000000001\n",
      "\n",
      "Validation loss: 0.1006370335817337\n",
      "Accuracy on validation set: 0.9702\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.1229894831776619\n",
      "Accuracy on training set: 0.96342\n",
      "\n",
      "Validation loss: 0.0929226502776146\n",
      "Accuracy on validation set: 0.9727\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.1226886734366417\n",
      "Accuracy on training set: 0.96324\n",
      "\n",
      "Validation loss: 0.09440963715314865\n",
      "Accuracy on validation set: 0.9709\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.12205374240875244\n",
      "Accuracy on training set: 0.96302\n",
      "\n",
      "Validation loss: 0.0905447006225586\n",
      "Accuracy on validation set: 0.9739\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.12437047064304352\n",
      "Accuracy on training set: 0.9619\n",
      "\n",
      "Validation loss: 0.102824367582798\n",
      "Accuracy on validation set: 0.9685\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.12018821388483047\n",
      "Accuracy on training set: 0.96408\n",
      "\n",
      "Validation loss: 0.08877166360616684\n",
      "Accuracy on validation set: 0.9745\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.1226745992898941\n",
      "Accuracy on training set: 0.96318\n",
      "\n",
      "Validation loss: 0.08986174315214157\n",
      "Accuracy on validation set: 0.9731\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.12217028439044952\n",
      "Accuracy on training set: 0.9634000000000001\n",
      "\n",
      "Validation loss: 0.08503910899162292\n",
      "Accuracy on validation set: 0.9767\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.08503910899162292\n",
      "Final accuracy on validation set: 0.9767\n",
      "\n",
      "\n",
      "##### MODEL: 11/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0.001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': ReLU()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.5523248910903931\n",
      "Accuracy on training set: 0.8303800000000001\n",
      "\n",
      "Validation loss: 0.24968087673187256\n",
      "Accuracy on validation set: 0.9239\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.3754895329475403\n",
      "Accuracy on training set: 0.88958\n",
      "\n",
      "Validation loss: 0.22036586701869965\n",
      "Accuracy on validation set: 0.9353\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.34724920988082886\n",
      "Accuracy on training set: 0.8977\n",
      "\n",
      "Validation loss: 0.2684768736362457\n",
      "Accuracy on validation set: 0.9269\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.3317689001560211\n",
      "Accuracy on training set: 0.90144\n",
      "\n",
      "Validation loss: 0.1842731386423111\n",
      "Accuracy on validation set: 0.9437\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.32128801941871643\n",
      "Accuracy on training set: 0.9051800000000001\n",
      "\n",
      "Validation loss: 0.18418730795383453\n",
      "Accuracy on validation set: 0.946\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.31569620966911316\n",
      "Accuracy on training set: 0.9061600000000001\n",
      "\n",
      "Validation loss: 0.18221445381641388\n",
      "Accuracy on validation set: 0.9476\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.317534476518631\n",
      "Accuracy on training set: 0.90528\n",
      "\n",
      "Validation loss: 0.18787039816379547\n",
      "Accuracy on validation set: 0.9428\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.3115946650505066\n",
      "Accuracy on training set: 0.9073199999999999\n",
      "\n",
      "Validation loss: 0.1950162947177887\n",
      "Accuracy on validation set: 0.9412\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.3106743097305298\n",
      "Accuracy on training set: 0.90898\n",
      "\n",
      "Validation loss: 0.203755185008049\n",
      "Accuracy on validation set: 0.9409\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.31282567977905273\n",
      "Accuracy on training set: 0.9062\n",
      "\n",
      "Validation loss: 0.17553821206092834\n",
      "Accuracy on validation set: 0.9472\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.3039117753505707\n",
      "Accuracy on training set: 0.91182\n",
      "\n",
      "Validation loss: 0.1721249222755432\n",
      "Accuracy on validation set: 0.9493\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.3061235845088959\n",
      "Accuracy on training set: 0.9101\n",
      "\n",
      "Validation loss: 0.17357271909713745\n",
      "Accuracy on validation set: 0.95\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.30166879296302795\n",
      "Accuracy on training set: 0.9109400000000001\n",
      "\n",
      "Validation loss: 0.21127937734127045\n",
      "Accuracy on validation set: 0.932\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.2989053428173065\n",
      "Accuracy on training set: 0.9116400000000001\n",
      "\n",
      "Validation loss: 0.17447848618030548\n",
      "Accuracy on validation set: 0.9495\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.29930809140205383\n",
      "Accuracy on training set: 0.9115999999999999\n",
      "\n",
      "Validation loss: 0.21288830041885376\n",
      "Accuracy on validation set: 0.9346\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.29794561862945557\n",
      "Accuracy on training set: 0.91412\n",
      "\n",
      "Validation loss: 0.17202472686767578\n",
      "Accuracy on validation set: 0.9511\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.3006761372089386\n",
      "Accuracy on training set: 0.9110199999999999\n",
      "\n",
      "Validation loss: 0.17675764858722687\n",
      "Accuracy on validation set: 0.9461\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.29849183559417725\n",
      "Accuracy on training set: 0.9112400000000002\n",
      "\n",
      "Validation loss: 0.1869746893644333\n",
      "Accuracy on validation set: 0.9442\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.2975207269191742\n",
      "Accuracy on training set: 0.9119599999999999\n",
      "\n",
      "Validation loss: 0.1904463917016983\n",
      "Accuracy on validation set: 0.9419\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.2979521155357361\n",
      "Accuracy on training set: 0.91228\n",
      "\n",
      "Validation loss: 0.16875316202640533\n",
      "Accuracy on validation set: 0.948\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.29979178309440613\n",
      "Accuracy on training set: 0.91298\n",
      "\n",
      "Validation loss: 0.17491024732589722\n",
      "Accuracy on validation set: 0.9486\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.29608169198036194\n",
      "Accuracy on training set: 0.9124200000000001\n",
      "\n",
      "Validation loss: 0.18760764598846436\n",
      "Accuracy on validation set: 0.9452\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.29531610012054443\n",
      "Accuracy on training set: 0.91246\n",
      "\n",
      "Validation loss: 0.1891174167394638\n",
      "Accuracy on validation set: 0.9429\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.29591119289398193\n",
      "Accuracy on training set: 0.91222\n",
      "\n",
      "Validation loss: 0.19384042918682098\n",
      "Accuracy on validation set: 0.9427\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.29753321409225464\n",
      "Accuracy on training set: 0.91224\n",
      "\n",
      "Validation loss: 0.18815253674983978\n",
      "Accuracy on validation set: 0.9409\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.29897597432136536\n",
      "Accuracy on training set: 0.91272\n",
      "\n",
      "Validation loss: 0.1768607348203659\n",
      "Accuracy on validation set: 0.9477\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.2980057895183563\n",
      "Accuracy on training set: 0.9112800000000001\n",
      "\n",
      "Validation loss: 0.16971828043460846\n",
      "Accuracy on validation set: 0.9521\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.30015283823013306\n",
      "Accuracy on training set: 0.91174\n",
      "\n",
      "Validation loss: 0.17611366510391235\n",
      "Accuracy on validation set: 0.9477\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.30143678188323975\n",
      "Accuracy on training set: 0.9124200000000001\n",
      "\n",
      "Validation loss: 0.17069417238235474\n",
      "Accuracy on validation set: 0.9483\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.2989100217819214\n",
      "Accuracy on training set: 0.9101600000000001\n",
      "\n",
      "Validation loss: 0.16455857455730438\n",
      "Accuracy on validation set: 0.9527\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.16455857455730438\n",
      "Final accuracy on validation set: 0.9527\n",
      "\n",
      "\n",
      "##### MODEL: 12/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0.0001, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': ReLU()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.5680481791496277\n",
      "Accuracy on training set: 0.82882\n",
      "\n",
      "Validation loss: 0.23134997487068176\n",
      "Accuracy on validation set: 0.9296\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.2953127920627594\n",
      "Accuracy on training set: 0.9127799999999999\n",
      "\n",
      "Validation loss: 0.17959916591644287\n",
      "Accuracy on validation set: 0.9467\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.2401946783065796\n",
      "Accuracy on training set: 0.92974\n",
      "\n",
      "Validation loss: 0.1513667106628418\n",
      "Accuracy on validation set: 0.9534\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.20924296975135803\n",
      "Accuracy on training set: 0.9388599999999999\n",
      "\n",
      "Validation loss: 0.13330788910388947\n",
      "Accuracy on validation set: 0.9595\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.19438832998275757\n",
      "Accuracy on training set: 0.9422200000000001\n",
      "\n",
      "Validation loss: 0.12280935049057007\n",
      "Accuracy on validation set: 0.9629\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.18203485012054443\n",
      "Accuracy on training set: 0.9457000000000001\n",
      "\n",
      "Validation loss: 0.11238011717796326\n",
      "Accuracy on validation set: 0.9662\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.1727069765329361\n",
      "Accuracy on training set: 0.9485399999999999\n",
      "\n",
      "Validation loss: 0.1085520014166832\n",
      "Accuracy on validation set: 0.9663\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.16197611391544342\n",
      "Accuracy on training set: 0.95096\n",
      "\n",
      "Validation loss: 0.1085292249917984\n",
      "Accuracy on validation set: 0.9665\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.15952441096305847\n",
      "Accuracy on training set: 0.9517\n",
      "\n",
      "Validation loss: 0.11007198691368103\n",
      "Accuracy on validation set: 0.9679\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.15070991218090057\n",
      "Accuracy on training set: 0.95372\n",
      "\n",
      "Validation loss: 0.10895678400993347\n",
      "Accuracy on validation set: 0.968\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.14831024408340454\n",
      "Accuracy on training set: 0.95484\n",
      "\n",
      "Validation loss: 0.09866685420274734\n",
      "Accuracy on validation set: 0.9691\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.1453944891691208\n",
      "Accuracy on training set: 0.95494\n",
      "\n",
      "Validation loss: 0.10227485001087189\n",
      "Accuracy on validation set: 0.9692\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.1396433711051941\n",
      "Accuracy on training set: 0.9577\n",
      "\n",
      "Validation loss: 0.10222824662923813\n",
      "Accuracy on validation set: 0.969\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.13583172857761383\n",
      "Accuracy on training set: 0.9582\n",
      "\n",
      "Validation loss: 0.1059354618191719\n",
      "Accuracy on validation set: 0.9676\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.13387992978096008\n",
      "Accuracy on training set: 0.95796\n",
      "\n",
      "Validation loss: 0.0987580269575119\n",
      "Accuracy on validation set: 0.9694\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.13060204684734344\n",
      "Accuracy on training set: 0.9596\n",
      "\n",
      "Validation loss: 0.09866826236248016\n",
      "Accuracy on validation set: 0.9702\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.12853167951107025\n",
      "Accuracy on training set: 0.95998\n",
      "\n",
      "Validation loss: 0.10336047410964966\n",
      "Accuracy on validation set: 0.9689\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.12781548500061035\n",
      "Accuracy on training set: 0.96072\n",
      "\n",
      "Validation loss: 0.09601102024316788\n",
      "Accuracy on validation set: 0.9708\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.12634801864624023\n",
      "Accuracy on training set: 0.9616399999999999\n",
      "\n",
      "Validation loss: 0.09546354413032532\n",
      "Accuracy on validation set: 0.9724\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.12460501492023468\n",
      "Accuracy on training set: 0.9615199999999999\n",
      "\n",
      "Validation loss: 0.09901659190654755\n",
      "Accuracy on validation set: 0.9703\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.1219979003071785\n",
      "Accuracy on training set: 0.9624000000000001\n",
      "\n",
      "Validation loss: 0.09816879034042358\n",
      "Accuracy on validation set: 0.9703\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.12164663523435593\n",
      "Accuracy on training set: 0.9620599999999999\n",
      "\n",
      "Validation loss: 0.09434108436107635\n",
      "Accuracy on validation set: 0.9714\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.1198967844247818\n",
      "Accuracy on training set: 0.9625400000000001\n",
      "\n",
      "Validation loss: 0.09379183501005173\n",
      "Accuracy on validation set: 0.9712\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.11972272396087646\n",
      "Accuracy on training set: 0.96246\n",
      "\n",
      "Validation loss: 0.0949450433254242\n",
      "Accuracy on validation set: 0.972\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.11624915897846222\n",
      "Accuracy on training set: 0.9640800000000002\n",
      "\n",
      "Validation loss: 0.09505801647901535\n",
      "Accuracy on validation set: 0.9721\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.11736488342285156\n",
      "Accuracy on training set: 0.9636200000000001\n",
      "\n",
      "Validation loss: 0.09489991515874863\n",
      "Accuracy on validation set: 0.9724\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.11653070896863937\n",
      "Accuracy on training set: 0.96354\n",
      "\n",
      "Validation loss: 0.09514414519071579\n",
      "Accuracy on validation set: 0.9724\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.11753779649734497\n",
      "Accuracy on training set: 0.9638800000000001\n",
      "\n",
      "Validation loss: 0.10189428180456161\n",
      "Accuracy on validation set: 0.9712\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.1117062121629715\n",
      "Accuracy on training set: 0.9645800000000001\n",
      "\n",
      "Validation loss: 0.0934942439198494\n",
      "Accuracy on validation set: 0.9724\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.11268441379070282\n",
      "Accuracy on training set: 0.96342\n",
      "\n",
      "Validation loss: 0.09673714637756348\n",
      "Accuracy on validation set: 0.9727\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.09673714637756348\n",
      "Final accuracy on validation set: 0.9727\n",
      "\n",
      "\n",
      "##### MODEL: 13/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0.0001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.36496302485466003\n",
      "Accuracy on training set: 0.8875\n",
      "\n",
      "Validation loss: 0.19844965636730194\n",
      "Accuracy on validation set: 0.9387\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.22164615988731384\n",
      "Accuracy on training set: 0.9326199999999999\n",
      "\n",
      "Validation loss: 0.1549912542104721\n",
      "Accuracy on validation set: 0.9527\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.19787825644016266\n",
      "Accuracy on training set: 0.93924\n",
      "\n",
      "Validation loss: 0.1759156584739685\n",
      "Accuracy on validation set: 0.9457\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.18689194321632385\n",
      "Accuracy on training set: 0.94366\n",
      "\n",
      "Validation loss: 0.13471323251724243\n",
      "Accuracy on validation set: 0.9608\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.17974373698234558\n",
      "Accuracy on training set: 0.94514\n",
      "\n",
      "Validation loss: 0.13075152039527893\n",
      "Accuracy on validation set: 0.9614\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.1759643852710724\n",
      "Accuracy on training set: 0.94608\n",
      "\n",
      "Validation loss: 0.11282788962125778\n",
      "Accuracy on validation set: 0.9651\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.17591649293899536\n",
      "Accuracy on training set: 0.9455399999999999\n",
      "\n",
      "Validation loss: 0.13103164732456207\n",
      "Accuracy on validation set: 0.9586\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.17149768769741058\n",
      "Accuracy on training set: 0.94804\n",
      "\n",
      "Validation loss: 0.12325460463762283\n",
      "Accuracy on validation set: 0.9637\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.17098788917064667\n",
      "Accuracy on training set: 0.9475999999999999\n",
      "\n",
      "Validation loss: 0.11288554966449738\n",
      "Accuracy on validation set: 0.9651\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.1700701266527176\n",
      "Accuracy on training set: 0.94802\n",
      "\n",
      "Validation loss: 0.12113218009471893\n",
      "Accuracy on validation set: 0.9623\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.16472314298152924\n",
      "Accuracy on training set: 0.9485800000000001\n",
      "\n",
      "Validation loss: 0.12017040699720383\n",
      "Accuracy on validation set: 0.9647\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.16831974685192108\n",
      "Accuracy on training set: 0.9486400000000001\n",
      "\n",
      "Validation loss: 0.11310825496912003\n",
      "Accuracy on validation set: 0.965\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.1671632081270218\n",
      "Accuracy on training set: 0.9485399999999999\n",
      "\n",
      "Validation loss: 0.112571582198143\n",
      "Accuracy on validation set: 0.9647\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.16627074778079987\n",
      "Accuracy on training set: 0.9479\n",
      "\n",
      "Validation loss: 0.11667032539844513\n",
      "Accuracy on validation set: 0.9641\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.16453762352466583\n",
      "Accuracy on training set: 0.9494400000000001\n",
      "\n",
      "Validation loss: 0.11243995279073715\n",
      "Accuracy on validation set: 0.9644\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.16607840359210968\n",
      "Accuracy on training set: 0.9495\n",
      "\n",
      "Validation loss: 0.113917775452137\n",
      "Accuracy on validation set: 0.9636\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.16774670779705048\n",
      "Accuracy on training set: 0.94808\n",
      "\n",
      "Validation loss: 0.10814622789621353\n",
      "Accuracy on validation set: 0.9692\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.16623306274414062\n",
      "Accuracy on training set: 0.9489200000000001\n",
      "\n",
      "Validation loss: 0.13152505457401276\n",
      "Accuracy on validation set: 0.959\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.16574199497699738\n",
      "Accuracy on training set: 0.94834\n",
      "\n",
      "Validation loss: 0.1338958442211151\n",
      "Accuracy on validation set: 0.9593\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.1632334589958191\n",
      "Accuracy on training set: 0.9496800000000001\n",
      "\n",
      "Validation loss: 0.11995261162519455\n",
      "Accuracy on validation set: 0.9629\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.16488268971443176\n",
      "Accuracy on training set: 0.94924\n",
      "\n",
      "Validation loss: 0.1090114414691925\n",
      "Accuracy on validation set: 0.9662\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.16303567588329315\n",
      "Accuracy on training set: 0.9496600000000001\n",
      "\n",
      "Validation loss: 0.11443347483873367\n",
      "Accuracy on validation set: 0.9652\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.16540782153606415\n",
      "Accuracy on training set: 0.94904\n",
      "\n",
      "Validation loss: 0.11767802387475967\n",
      "Accuracy on validation set: 0.963\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.16095934808254242\n",
      "Accuracy on training set: 0.94934\n",
      "\n",
      "Validation loss: 0.10748474299907684\n",
      "Accuracy on validation set: 0.9697\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.16173219680786133\n",
      "Accuracy on training set: 0.95018\n",
      "\n",
      "Validation loss: 0.12144388258457184\n",
      "Accuracy on validation set: 0.9609\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.15955734252929688\n",
      "Accuracy on training set: 0.9504600000000001\n",
      "\n",
      "Validation loss: 0.11767209321260452\n",
      "Accuracy on validation set: 0.963\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.1626022607088089\n",
      "Accuracy on training set: 0.9491400000000001\n",
      "\n",
      "Validation loss: 0.11889353394508362\n",
      "Accuracy on validation set: 0.9631\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.16295364499092102\n",
      "Accuracy on training set: 0.9506\n",
      "\n",
      "Validation loss: 0.10735291987657547\n",
      "Accuracy on validation set: 0.9684\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.1643396019935608\n",
      "Accuracy on training set: 0.9501600000000001\n",
      "\n",
      "Validation loss: 0.12043388932943344\n",
      "Accuracy on validation set: 0.9632\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.16263331472873688\n",
      "Accuracy on training set: 0.94948\n",
      "\n",
      "Validation loss: 0.11079771816730499\n",
      "Accuracy on validation set: 0.9653\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.11079771816730499\n",
      "Final accuracy on validation set: 0.9653\n",
      "\n",
      "\n",
      "##### MODEL: 14/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0.0001, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.3934836983680725\n",
      "Accuracy on training set: 0.8856200000000001\n",
      "\n",
      "Validation loss: 0.17948491871356964\n",
      "Accuracy on validation set: 0.9454\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.15385802090168\n",
      "Accuracy on training set: 0.95448\n",
      "\n",
      "Validation loss: 0.13568630814552307\n",
      "Accuracy on validation set: 0.9573\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.12267925590276718\n",
      "Accuracy on training set: 0.96308\n",
      "\n",
      "Validation loss: 0.12450268864631653\n",
      "Accuracy on validation set: 0.9624\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.10560955852270126\n",
      "Accuracy on training set: 0.96802\n",
      "\n",
      "Validation loss: 0.11684035509824753\n",
      "Accuracy on validation set: 0.9653\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.09844259917736053\n",
      "Accuracy on training set: 0.9690200000000001\n",
      "\n",
      "Validation loss: 0.10686752945184708\n",
      "Accuracy on validation set: 0.9685\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.09181398153305054\n",
      "Accuracy on training set: 0.97124\n",
      "\n",
      "Validation loss: 0.11981547623872757\n",
      "Accuracy on validation set: 0.9632\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.08918242156505585\n",
      "Accuracy on training set: 0.9731600000000001\n",
      "\n",
      "Validation loss: 0.1050795167684555\n",
      "Accuracy on validation set: 0.9662\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.08363621681928635\n",
      "Accuracy on training set: 0.9746\n",
      "\n",
      "Validation loss: 0.10382246226072311\n",
      "Accuracy on validation set: 0.9681\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.08171936124563217\n",
      "Accuracy on training set: 0.97522\n",
      "\n",
      "Validation loss: 0.12381482124328613\n",
      "Accuracy on validation set: 0.9619\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.08436398953199387\n",
      "Accuracy on training set: 0.9733800000000001\n",
      "\n",
      "Validation loss: 0.11768492311239243\n",
      "Accuracy on validation set: 0.9643\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.07942192256450653\n",
      "Accuracy on training set: 0.9749200000000001\n",
      "\n",
      "Validation loss: 0.10397310554981232\n",
      "Accuracy on validation set: 0.9683\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.07799062132835388\n",
      "Accuracy on training set: 0.9756200000000002\n",
      "\n",
      "Validation loss: 0.11427458375692368\n",
      "Accuracy on validation set: 0.965\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.0765322595834732\n",
      "Accuracy on training set: 0.9760800000000002\n",
      "\n",
      "Validation loss: 0.10248363018035889\n",
      "Accuracy on validation set: 0.9695\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.07682261615991592\n",
      "Accuracy on training set: 0.9757\n",
      "\n",
      "Validation loss: 0.10176943987607956\n",
      "Accuracy on validation set: 0.9701\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.07674990594387054\n",
      "Accuracy on training set: 0.9758400000000002\n",
      "\n",
      "Validation loss: 0.10723967105150223\n",
      "Accuracy on validation set: 0.9669\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.07359446585178375\n",
      "Accuracy on training set: 0.9774400000000002\n",
      "\n",
      "Validation loss: 0.12245660275220871\n",
      "Accuracy on validation set: 0.9639\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.07850605994462967\n",
      "Accuracy on training set: 0.97506\n",
      "\n",
      "Validation loss: 0.16065716743469238\n",
      "Accuracy on validation set: 0.951\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.07655570656061172\n",
      "Accuracy on training set: 0.9762799999999999\n",
      "\n",
      "Validation loss: 0.10743381083011627\n",
      "Accuracy on validation set: 0.9676\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.0734516903758049\n",
      "Accuracy on training set: 0.9771000000000002\n",
      "\n",
      "Validation loss: 0.10774768143892288\n",
      "Accuracy on validation set: 0.967\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.0755932480096817\n",
      "Accuracy on training set: 0.9764200000000001\n",
      "\n",
      "Validation loss: 0.12324979156255722\n",
      "Accuracy on validation set: 0.961\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.0765957161784172\n",
      "Accuracy on training set: 0.9758200000000001\n",
      "\n",
      "Validation loss: 0.10311384499073029\n",
      "Accuracy on validation set: 0.9676\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.07200262695550919\n",
      "Accuracy on training set: 0.9772000000000002\n",
      "\n",
      "Validation loss: 0.09810616075992584\n",
      "Accuracy on validation set: 0.9685\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.07346507161855698\n",
      "Accuracy on training set: 0.9779200000000001\n",
      "\n",
      "Validation loss: 0.10058983415365219\n",
      "Accuracy on validation set: 0.9686\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.07252902537584305\n",
      "Accuracy on training set: 0.97724\n",
      "\n",
      "Validation loss: 0.10091989487409592\n",
      "Accuracy on validation set: 0.9695\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.07036871463060379\n",
      "Accuracy on training set: 0.9780600000000002\n",
      "\n",
      "Validation loss: 0.1251765936613083\n",
      "Accuracy on validation set: 0.962\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.07549966871738434\n",
      "Accuracy on training set: 0.9755\n",
      "\n",
      "Validation loss: 0.11303427815437317\n",
      "Accuracy on validation set: 0.966\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.07184678316116333\n",
      "Accuracy on training set: 0.9767\n",
      "\n",
      "Validation loss: 0.10563698410987854\n",
      "Accuracy on validation set: 0.9662\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.0713023841381073\n",
      "Accuracy on training set: 0.9777\n",
      "\n",
      "Validation loss: 0.11641184240579605\n",
      "Accuracy on validation set: 0.963\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.07028856128454208\n",
      "Accuracy on training set: 0.9778200000000001\n",
      "\n",
      "Validation loss: 0.11524869501590729\n",
      "Accuracy on validation set: 0.9652\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.07213789224624634\n",
      "Accuracy on training set: 0.9767400000000002\n",
      "\n",
      "Validation loss: 0.09740795195102692\n",
      "Accuracy on validation set: 0.9696\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.09740795195102692\n",
      "Final accuracy on validation set: 0.9696\n",
      "\n",
      "\n",
      "##### MODEL: 15/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0.0001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.47286155819892883\n",
      "Accuracy on training set: 0.8594400000000001\n",
      "\n",
      "Validation loss: 0.2204948514699936\n",
      "Accuracy on validation set: 0.9336\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.29447242617607117\n",
      "Accuracy on training set: 0.9141999999999999\n",
      "\n",
      "Validation loss: 0.17278563976287842\n",
      "Accuracy on validation set: 0.9493\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.2618716359138489\n",
      "Accuracy on training set: 0.9221\n",
      "\n",
      "Validation loss: 0.19031177461147308\n",
      "Accuracy on validation set: 0.9421\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.25254905223846436\n",
      "Accuracy on training set: 0.9252\n",
      "\n",
      "Validation loss: 0.14517226815223694\n",
      "Accuracy on validation set: 0.9549\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.24408935010433197\n",
      "Accuracy on training set: 0.9258399999999999\n",
      "\n",
      "Validation loss: 0.15458239614963531\n",
      "Accuracy on validation set: 0.9535\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.23600046336650848\n",
      "Accuracy on training set: 0.92936\n",
      "\n",
      "Validation loss: 0.1403731107711792\n",
      "Accuracy on validation set: 0.9557\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.23540045320987701\n",
      "Accuracy on training set: 0.93\n",
      "\n",
      "Validation loss: 0.14578668773174286\n",
      "Accuracy on validation set: 0.9573\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.23269495368003845\n",
      "Accuracy on training set: 0.92936\n",
      "\n",
      "Validation loss: 0.14710301160812378\n",
      "Accuracy on validation set: 0.9546\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.22830750048160553\n",
      "Accuracy on training set: 0.9305999999999999\n",
      "\n",
      "Validation loss: 0.1429777443408966\n",
      "Accuracy on validation set: 0.9565\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.22670194506645203\n",
      "Accuracy on training set: 0.93196\n",
      "\n",
      "Validation loss: 0.14285747706890106\n",
      "Accuracy on validation set: 0.9545\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.21915993094444275\n",
      "Accuracy on training set: 0.9334000000000001\n",
      "\n",
      "Validation loss: 0.13734398782253265\n",
      "Accuracy on validation set: 0.957\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.22101467847824097\n",
      "Accuracy on training set: 0.934\n",
      "\n",
      "Validation loss: 0.13394367694854736\n",
      "Accuracy on validation set: 0.9588\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.21906308829784393\n",
      "Accuracy on training set: 0.9339\n",
      "\n",
      "Validation loss: 0.13895359635353088\n",
      "Accuracy on validation set: 0.9562\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.21544967591762543\n",
      "Accuracy on training set: 0.93526\n",
      "\n",
      "Validation loss: 0.126512810587883\n",
      "Accuracy on validation set: 0.9612\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.21379737555980682\n",
      "Accuracy on training set: 0.93398\n",
      "\n",
      "Validation loss: 0.13662350177764893\n",
      "Accuracy on validation set: 0.9563\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.2174898087978363\n",
      "Accuracy on training set: 0.93342\n",
      "\n",
      "Validation loss: 0.1271095722913742\n",
      "Accuracy on validation set: 0.961\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.21370764076709747\n",
      "Accuracy on training set: 0.9354600000000001\n",
      "\n",
      "Validation loss: 0.13444264233112335\n",
      "Accuracy on validation set: 0.9587\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.21420352160930634\n",
      "Accuracy on training set: 0.9345399999999999\n",
      "\n",
      "Validation loss: 0.1351567804813385\n",
      "Accuracy on validation set: 0.9577\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.21034091711044312\n",
      "Accuracy on training set: 0.93592\n",
      "\n",
      "Validation loss: 0.1375778317451477\n",
      "Accuracy on validation set: 0.9566\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.21410317718982697\n",
      "Accuracy on training set: 0.93576\n",
      "\n",
      "Validation loss: 0.12309588491916656\n",
      "Accuracy on validation set: 0.9628\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.21397091448307037\n",
      "Accuracy on training set: 0.9350599999999999\n",
      "\n",
      "Validation loss: 0.12917450070381165\n",
      "Accuracy on validation set: 0.9601\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.21227215230464935\n",
      "Accuracy on training set: 0.93678\n",
      "\n",
      "Validation loss: 0.12477447837591171\n",
      "Accuracy on validation set: 0.9603\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.20975899696350098\n",
      "Accuracy on training set: 0.93602\n",
      "\n",
      "Validation loss: 0.1484488695859909\n",
      "Accuracy on validation set: 0.9555\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.20980863273143768\n",
      "Accuracy on training set: 0.9354000000000001\n",
      "\n",
      "Validation loss: 0.12094725668430328\n",
      "Accuracy on validation set: 0.9629\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.20919980108737946\n",
      "Accuracy on training set: 0.93582\n",
      "\n",
      "Validation loss: 0.1363353431224823\n",
      "Accuracy on validation set: 0.9557\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.21124112606048584\n",
      "Accuracy on training set: 0.93648\n",
      "\n",
      "Validation loss: 0.13082382082939148\n",
      "Accuracy on validation set: 0.9603\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.20694370567798615\n",
      "Accuracy on training set: 0.93652\n",
      "\n",
      "Validation loss: 0.12316177040338516\n",
      "Accuracy on validation set: 0.9612\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.21080832183361053\n",
      "Accuracy on training set: 0.93602\n",
      "\n",
      "Validation loss: 0.12136927247047424\n",
      "Accuracy on validation set: 0.9625\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.20742888748645782\n",
      "Accuracy on training set: 0.93708\n",
      "\n",
      "Validation loss: 0.12202981859445572\n",
      "Accuracy on validation set: 0.9621\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.2065647840499878\n",
      "Accuracy on training set: 0.936\n",
      "\n",
      "Validation loss: 0.11574149131774902\n",
      "Accuracy on validation set: 0.9649\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.11574149131774902\n",
      "Final accuracy on validation set: 0.9649\n",
      "\n",
      "\n",
      "##### MODEL: 16/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.6451854705810547\n",
      "Accuracy on training set: 0.83318\n",
      "\n",
      "Validation loss: 0.31942930817604065\n",
      "Accuracy on validation set: 0.9107\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.26131078600883484\n",
      "Accuracy on training set: 0.9244\n",
      "\n",
      "Validation loss: 0.22802871465682983\n",
      "Accuracy on validation set: 0.9345\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.19146496057510376\n",
      "Accuracy on training set: 0.94448\n",
      "\n",
      "Validation loss: 0.18874871730804443\n",
      "Accuracy on validation set: 0.9437\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.15047448873519897\n",
      "Accuracy on training set: 0.9566800000000001\n",
      "\n",
      "Validation loss: 0.1517343521118164\n",
      "Accuracy on validation set: 0.9551\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.12262891978025436\n",
      "Accuracy on training set: 0.9642200000000001\n",
      "\n",
      "Validation loss: 0.1333095133304596\n",
      "Accuracy on validation set: 0.9604\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.1032891646027565\n",
      "Accuracy on training set: 0.96948\n",
      "\n",
      "Validation loss: 0.12221724539995193\n",
      "Accuracy on validation set: 0.9619\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.08827459812164307\n",
      "Accuracy on training set: 0.9743800000000001\n",
      "\n",
      "Validation loss: 0.11661949753761292\n",
      "Accuracy on validation set: 0.9638\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.0768190398812294\n",
      "Accuracy on training set: 0.9778600000000002\n",
      "\n",
      "Validation loss: 0.11002154648303986\n",
      "Accuracy on validation set: 0.9658\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.06773136556148529\n",
      "Accuracy on training set: 0.9802200000000001\n",
      "\n",
      "Validation loss: 0.10953114181756973\n",
      "Accuracy on validation set: 0.9668\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.059607118368148804\n",
      "Accuracy on training set: 0.9827800000000002\n",
      "\n",
      "Validation loss: 0.10664311796426773\n",
      "Accuracy on validation set: 0.9675\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.05274839326739311\n",
      "Accuracy on training set: 0.9852600000000001\n",
      "\n",
      "Validation loss: 0.10028264671564102\n",
      "Accuracy on validation set: 0.9701\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.04643635451793671\n",
      "Accuracy on training set: 0.9871400000000001\n",
      "\n",
      "Validation loss: 0.10308245569467545\n",
      "Accuracy on validation set: 0.97\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.04164953902363777\n",
      "Accuracy on training set: 0.9887\n",
      "\n",
      "Validation loss: 0.0993049144744873\n",
      "Accuracy on validation set: 0.9707\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.0374055840075016\n",
      "Accuracy on training set: 0.9901800000000001\n",
      "\n",
      "Validation loss: 0.10085749626159668\n",
      "Accuracy on validation set: 0.9696\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.03355124220252037\n",
      "Accuracy on training set: 0.9907800000000002\n",
      "\n",
      "Validation loss: 0.10126844793558121\n",
      "Accuracy on validation set: 0.9712\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.02932014688849449\n",
      "Accuracy on training set: 0.9920400000000001\n",
      "\n",
      "Validation loss: 0.10303709656000137\n",
      "Accuracy on validation set: 0.9697\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.02610301785171032\n",
      "Accuracy on training set: 0.9933600000000001\n",
      "\n",
      "Validation loss: 0.11095499247312546\n",
      "Accuracy on validation set: 0.9692\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.022987419739365578\n",
      "Accuracy on training set: 0.9944000000000001\n",
      "\n",
      "Validation loss: 0.11475584656000137\n",
      "Accuracy on validation set: 0.9687\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.020425552502274513\n",
      "Accuracy on training set: 0.99474\n",
      "\n",
      "Validation loss: 0.10865338146686554\n",
      "Accuracy on validation set: 0.9701\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.01753326691687107\n",
      "Accuracy on training set: 0.9961000000000001\n",
      "\n",
      "Validation loss: 0.1119610071182251\n",
      "Accuracy on validation set: 0.9696\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.01597483828663826\n",
      "Accuracy on training set: 0.9959600000000001\n",
      "\n",
      "Validation loss: 0.11163022369146347\n",
      "Accuracy on validation set: 0.97\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.013520139269530773\n",
      "Accuracy on training set: 0.99702\n",
      "\n",
      "Validation loss: 0.1130916029214859\n",
      "Accuracy on validation set: 0.9708\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.012330615893006325\n",
      "Accuracy on training set: 0.9973000000000001\n",
      "\n",
      "Validation loss: 0.11910455673933029\n",
      "Accuracy on validation set: 0.9695\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.010662062093615532\n",
      "Accuracy on training set: 0.9977999999999999\n",
      "\n",
      "Validation loss: 0.12094840407371521\n",
      "Accuracy on validation set: 0.9714\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.009020078927278519\n",
      "Accuracy on training set: 0.99822\n",
      "\n",
      "Validation loss: 0.1266867071390152\n",
      "Accuracy on validation set: 0.9705\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.007822945713996887\n",
      "Accuracy on training set: 0.9984400000000001\n",
      "\n",
      "Validation loss: 0.1321428269147873\n",
      "Accuracy on validation set: 0.9693\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.007486185524612665\n",
      "Accuracy on training set: 0.99846\n",
      "\n",
      "Validation loss: 0.1313144713640213\n",
      "Accuracy on validation set: 0.9705\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.006302976980805397\n",
      "Accuracy on training set: 0.99892\n",
      "\n",
      "Validation loss: 0.1358303278684616\n",
      "Accuracy on validation set: 0.9692\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.005360580515116453\n",
      "Accuracy on training set: 0.9990999999999999\n",
      "\n",
      "Validation loss: 0.13524438440799713\n",
      "Accuracy on validation set: 0.9694\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.004605334717780352\n",
      "Accuracy on training set: 0.99916\n",
      "\n",
      "Validation loss: 0.14123836159706116\n",
      "Accuracy on validation set: 0.97\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.14123836159706116\n",
      "Final accuracy on validation set: 0.97\n",
      "\n",
      "\n",
      "##### MODEL: 17/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0.0001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': ReLU()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.3671664595603943\n",
      "Accuracy on training set: 0.8890800000000001\n",
      "\n",
      "Validation loss: 0.16864889860153198\n",
      "Accuracy on validation set: 0.9487\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.2016066610813141\n",
      "Accuracy on training set: 0.9398200000000002\n",
      "\n",
      "Validation loss: 0.12785907089710236\n",
      "Accuracy on validation set: 0.9586\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.15833745896816254\n",
      "Accuracy on training set: 0.9527\n",
      "\n",
      "Validation loss: 0.11466901749372482\n",
      "Accuracy on validation set: 0.9633\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.13807374238967896\n",
      "Accuracy on training set: 0.95886\n",
      "\n",
      "Validation loss: 0.09833920747041702\n",
      "Accuracy on validation set: 0.9696\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.12188276648521423\n",
      "Accuracy on training set: 0.96302\n",
      "\n",
      "Validation loss: 0.09003231674432755\n",
      "Accuracy on validation set: 0.973\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.11327539384365082\n",
      "Accuracy on training set: 0.96564\n",
      "\n",
      "Validation loss: 0.08732388913631439\n",
      "Accuracy on validation set: 0.974\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.10567906498908997\n",
      "Accuracy on training set: 0.9676\n",
      "\n",
      "Validation loss: 0.09113120287656784\n",
      "Accuracy on validation set: 0.9736\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.10013813525438309\n",
      "Accuracy on training set: 0.9689000000000001\n",
      "\n",
      "Validation loss: 0.08355505019426346\n",
      "Accuracy on validation set: 0.976\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.09718558937311172\n",
      "Accuracy on training set: 0.97038\n",
      "\n",
      "Validation loss: 0.08323545753955841\n",
      "Accuracy on validation set: 0.9762\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.09281062334775925\n",
      "Accuracy on training set: 0.9720400000000001\n",
      "\n",
      "Validation loss: 0.08034075051546097\n",
      "Accuracy on validation set: 0.9749\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.08983878046274185\n",
      "Accuracy on training set: 0.9725\n",
      "\n",
      "Validation loss: 0.07823832333087921\n",
      "Accuracy on validation set: 0.9766\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.08917439728975296\n",
      "Accuracy on training set: 0.9721600000000001\n",
      "\n",
      "Validation loss: 0.08342142403125763\n",
      "Accuracy on validation set: 0.9756\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.08500050753355026\n",
      "Accuracy on training set: 0.9734200000000001\n",
      "\n",
      "Validation loss: 0.08018878847360611\n",
      "Accuracy on validation set: 0.9785\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.08149831742048264\n",
      "Accuracy on training set: 0.9734\n",
      "\n",
      "Validation loss: 0.07851335406303406\n",
      "Accuracy on validation set: 0.9777\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.08039841055870056\n",
      "Accuracy on training set: 0.9744400000000001\n",
      "\n",
      "Validation loss: 0.07982758432626724\n",
      "Accuracy on validation set: 0.9772\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.07744524627923965\n",
      "Accuracy on training set: 0.97546\n",
      "\n",
      "Validation loss: 0.0802946537733078\n",
      "Accuracy on validation set: 0.9765\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.07846216857433319\n",
      "Accuracy on training set: 0.9746600000000001\n",
      "\n",
      "Validation loss: 0.08448087424039841\n",
      "Accuracy on validation set: 0.9763\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.07438575476408005\n",
      "Accuracy on training set: 0.9773600000000001\n",
      "\n",
      "Validation loss: 0.08211573958396912\n",
      "Accuracy on validation set: 0.9766\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.07561662048101425\n",
      "Accuracy on training set: 0.9764800000000001\n",
      "\n",
      "Validation loss: 0.07645493745803833\n",
      "Accuracy on validation set: 0.9785\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.07505662739276886\n",
      "Accuracy on training set: 0.9758400000000002\n",
      "\n",
      "Validation loss: 0.07910473644733429\n",
      "Accuracy on validation set: 0.9776\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.07637762278318405\n",
      "Accuracy on training set: 0.9754400000000001\n",
      "\n",
      "Validation loss: 0.07688383013010025\n",
      "Accuracy on validation set: 0.9792\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.07253352552652359\n",
      "Accuracy on training set: 0.9763800000000001\n",
      "\n",
      "Validation loss: 0.08031373471021652\n",
      "Accuracy on validation set: 0.9786\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.06982561945915222\n",
      "Accuracy on training set: 0.9785400000000001\n",
      "\n",
      "Validation loss: 0.0799996629357338\n",
      "Accuracy on validation set: 0.9787\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.07159797102212906\n",
      "Accuracy on training set: 0.9768000000000002\n",
      "\n",
      "Validation loss: 0.07618718594312668\n",
      "Accuracy on validation set: 0.9806\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.07123933732509613\n",
      "Accuracy on training set: 0.9776400000000001\n",
      "\n",
      "Validation loss: 0.07652218639850616\n",
      "Accuracy on validation set: 0.9786\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.06748384237289429\n",
      "Accuracy on training set: 0.97828\n",
      "\n",
      "Validation loss: 0.07586793601512909\n",
      "Accuracy on validation set: 0.9789\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.06821124255657196\n",
      "Accuracy on training set: 0.97816\n",
      "\n",
      "Validation loss: 0.08129043132066727\n",
      "Accuracy on validation set: 0.9774\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.068353071808815\n",
      "Accuracy on training set: 0.97816\n",
      "\n",
      "Validation loss: 0.0755339190363884\n",
      "Accuracy on validation set: 0.9799\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.06824412196874619\n",
      "Accuracy on training set: 0.9780200000000001\n",
      "\n",
      "Validation loss: 0.07884936779737473\n",
      "Accuracy on validation set: 0.9784\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.06976453959941864\n",
      "Accuracy on training set: 0.9779000000000001\n",
      "\n",
      "Validation loss: 0.07522878050804138\n",
      "Accuracy on validation set: 0.9791\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.07522878050804138\n",
      "Final accuracy on validation set: 0.9791\n",
      "\n",
      "\n",
      "##### MODEL: 18/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 1.0444755554199219\n",
      "Accuracy on training set: 0.6912999999999999\n",
      "\n",
      "Validation loss: 0.41425371170043945\n",
      "Accuracy on validation set: 0.8906\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.44205620884895325\n",
      "Accuracy on training set: 0.87672\n",
      "\n",
      "Validation loss: 0.29544001817703247\n",
      "Accuracy on validation set: 0.9161\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.3562988042831421\n",
      "Accuracy on training set: 0.8978400000000001\n",
      "\n",
      "Validation loss: 0.24674203991889954\n",
      "Accuracy on validation set: 0.9283\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.3103131055831909\n",
      "Accuracy on training set: 0.9118200000000001\n",
      "\n",
      "Validation loss: 0.21645432710647583\n",
      "Accuracy on validation set: 0.9359\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.2819051146507263\n",
      "Accuracy on training set: 0.91744\n",
      "\n",
      "Validation loss: 0.19343343377113342\n",
      "Accuracy on validation set: 0.9446\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.26097577810287476\n",
      "Accuracy on training set: 0.9244\n",
      "\n",
      "Validation loss: 0.1758548468351364\n",
      "Accuracy on validation set: 0.9494\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.2416825294494629\n",
      "Accuracy on training set: 0.9307799999999999\n",
      "\n",
      "Validation loss: 0.16373537480831146\n",
      "Accuracy on validation set: 0.9524\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.22744226455688477\n",
      "Accuracy on training set: 0.9338\n",
      "\n",
      "Validation loss: 0.15477639436721802\n",
      "Accuracy on validation set: 0.954\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.21649567782878876\n",
      "Accuracy on training set: 0.93728\n",
      "\n",
      "Validation loss: 0.14759205281734467\n",
      "Accuracy on validation set: 0.9559\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.20441599190235138\n",
      "Accuracy on training set: 0.9391799999999999\n",
      "\n",
      "Validation loss: 0.14525799453258514\n",
      "Accuracy on validation set: 0.9562\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.19712485373020172\n",
      "Accuracy on training set: 0.9431600000000001\n",
      "\n",
      "Validation loss: 0.13544028997421265\n",
      "Accuracy on validation set: 0.9584\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.18698842823505402\n",
      "Accuracy on training set: 0.94452\n",
      "\n",
      "Validation loss: 0.12916365265846252\n",
      "Accuracy on validation set: 0.9615\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.18056760728359222\n",
      "Accuracy on training set: 0.9466\n",
      "\n",
      "Validation loss: 0.1262415051460266\n",
      "Accuracy on validation set: 0.9625\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.17658627033233643\n",
      "Accuracy on training set: 0.94748\n",
      "\n",
      "Validation loss: 0.12358091026544571\n",
      "Accuracy on validation set: 0.9637\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.17246346175670624\n",
      "Accuracy on training set: 0.9484600000000001\n",
      "\n",
      "Validation loss: 0.12054533511400223\n",
      "Accuracy on validation set: 0.9644\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.16857510805130005\n",
      "Accuracy on training set: 0.9494600000000001\n",
      "\n",
      "Validation loss: 0.11805654317140579\n",
      "Accuracy on validation set: 0.9643\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.162154421210289\n",
      "Accuracy on training set: 0.95064\n",
      "\n",
      "Validation loss: 0.11698374897241592\n",
      "Accuracy on validation set: 0.9638\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.1595274806022644\n",
      "Accuracy on training set: 0.95126\n",
      "\n",
      "Validation loss: 0.1140807494521141\n",
      "Accuracy on validation set: 0.9651\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.15416529774665833\n",
      "Accuracy on training set: 0.95382\n",
      "\n",
      "Validation loss: 0.11271268129348755\n",
      "Accuracy on validation set: 0.9661\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.1540054976940155\n",
      "Accuracy on training set: 0.9533400000000001\n",
      "\n",
      "Validation loss: 0.11418389528989792\n",
      "Accuracy on validation set: 0.9656\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.14742471277713776\n",
      "Accuracy on training set: 0.9552\n",
      "\n",
      "Validation loss: 0.10933253169059753\n",
      "Accuracy on validation set: 0.9667\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.14254453778266907\n",
      "Accuracy on training set: 0.9566200000000001\n",
      "\n",
      "Validation loss: 0.10896075516939163\n",
      "Accuracy on validation set: 0.9664\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.14055755734443665\n",
      "Accuracy on training set: 0.9568600000000002\n",
      "\n",
      "Validation loss: 0.11144262552261353\n",
      "Accuracy on validation set: 0.9655\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.1417914777994156\n",
      "Accuracy on training set: 0.95648\n",
      "\n",
      "Validation loss: 0.10743900388479233\n",
      "Accuracy on validation set: 0.9677\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.139221653342247\n",
      "Accuracy on training set: 0.9582800000000001\n",
      "\n",
      "Validation loss: 0.1061675027012825\n",
      "Accuracy on validation set: 0.9675\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.13811486959457397\n",
      "Accuracy on training set: 0.9584\n",
      "\n",
      "Validation loss: 0.10553276538848877\n",
      "Accuracy on validation set: 0.9685\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.13677896559238434\n",
      "Accuracy on training set: 0.95742\n",
      "\n",
      "Validation loss: 0.10442513227462769\n",
      "Accuracy on validation set: 0.9681\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.1318364292383194\n",
      "Accuracy on training set: 0.95906\n",
      "\n",
      "Validation loss: 0.1056167259812355\n",
      "Accuracy on validation set: 0.9678\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.12835925817489624\n",
      "Accuracy on training set: 0.96102\n",
      "\n",
      "Validation loss: 0.10273228585720062\n",
      "Accuracy on validation set: 0.9687\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.12782873213291168\n",
      "Accuracy on training set: 0.96096\n",
      "\n",
      "Validation loss: 0.10228494554758072\n",
      "Accuracy on validation set: 0.9697\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.10228494554758072\n",
      "Final accuracy on validation set: 0.9697\n",
      "\n",
      "\n",
      "##### MODEL: 19/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.31946471333503723\n",
      "Accuracy on training set: 0.9016000000000002\n",
      "\n",
      "Validation loss: 0.15432679653167725\n",
      "Accuracy on validation set: 0.9535\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.11875933408737183\n",
      "Accuracy on training set: 0.964\n",
      "\n",
      "Validation loss: 0.12410179525613785\n",
      "Accuracy on validation set: 0.9617\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.08257560431957245\n",
      "Accuracy on training set: 0.97452\n",
      "\n",
      "Validation loss: 0.0998743399977684\n",
      "Accuracy on validation set: 0.9709\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.06292452663183212\n",
      "Accuracy on training set: 0.9798600000000002\n",
      "\n",
      "Validation loss: 0.10753706097602844\n",
      "Accuracy on validation set: 0.9695\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.05193758010864258\n",
      "Accuracy on training set: 0.9831200000000001\n",
      "\n",
      "Validation loss: 0.10081157088279724\n",
      "Accuracy on validation set: 0.9712\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.044806282967329025\n",
      "Accuracy on training set: 0.98572\n",
      "\n",
      "Validation loss: 0.11517217755317688\n",
      "Accuracy on validation set: 0.966\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.03563149273395538\n",
      "Accuracy on training set: 0.98792\n",
      "\n",
      "Validation loss: 0.09851790219545364\n",
      "Accuracy on validation set: 0.9745\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.031321484595537186\n",
      "Accuracy on training set: 0.9901400000000001\n",
      "\n",
      "Validation loss: 0.10372303426265717\n",
      "Accuracy on validation set: 0.9718\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.02815384976565838\n",
      "Accuracy on training set: 0.99092\n",
      "\n",
      "Validation loss: 0.10881813615560532\n",
      "Accuracy on validation set: 0.9718\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.02689351886510849\n",
      "Accuracy on training set: 0.9908000000000002\n",
      "\n",
      "Validation loss: 0.10903120040893555\n",
      "Accuracy on validation set: 0.973\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.021088000386953354\n",
      "Accuracy on training set: 0.9927600000000001\n",
      "\n",
      "Validation loss: 0.1303521692752838\n",
      "Accuracy on validation set: 0.9681\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.021976539865136147\n",
      "Accuracy on training set: 0.99282\n",
      "\n",
      "Validation loss: 0.11479653418064117\n",
      "Accuracy on validation set: 0.9728\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.018861765041947365\n",
      "Accuracy on training set: 0.9935400000000001\n",
      "\n",
      "Validation loss: 0.14938151836395264\n",
      "Accuracy on validation set: 0.9668\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.02271772362291813\n",
      "Accuracy on training set: 0.9920599999999999\n",
      "\n",
      "Validation loss: 0.13262464106082916\n",
      "Accuracy on validation set: 0.9712\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.014906988479197025\n",
      "Accuracy on training set: 0.9947\n",
      "\n",
      "Validation loss: 0.11848551034927368\n",
      "Accuracy on validation set: 0.9734\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.013110696338117123\n",
      "Accuracy on training set: 0.9953600000000001\n",
      "\n",
      "Validation loss: 0.12561452388763428\n",
      "Accuracy on validation set: 0.9743\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.016467463225126266\n",
      "Accuracy on training set: 0.99468\n",
      "\n",
      "Validation loss: 0.12884801626205444\n",
      "Accuracy on validation set: 0.9734\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.017903761938214302\n",
      "Accuracy on training set: 0.9938400000000001\n",
      "\n",
      "Validation loss: 0.13651441037654877\n",
      "Accuracy on validation set: 0.9713\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.01407894678413868\n",
      "Accuracy on training set: 0.9953000000000001\n",
      "\n",
      "Validation loss: 0.1297430694103241\n",
      "Accuracy on validation set: 0.9752\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.015366972424089909\n",
      "Accuracy on training set: 0.99478\n",
      "\n",
      "Validation loss: 0.13875825703144073\n",
      "Accuracy on validation set: 0.9721\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.012718967162072659\n",
      "Accuracy on training set: 0.9954000000000001\n",
      "\n",
      "Validation loss: 0.13141705095767975\n",
      "Accuracy on validation set: 0.9735\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.013213842175900936\n",
      "Accuracy on training set: 0.99536\n",
      "\n",
      "Validation loss: 0.15431317687034607\n",
      "Accuracy on validation set: 0.97\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.013921979814767838\n",
      "Accuracy on training set: 0.9951000000000001\n",
      "\n",
      "Validation loss: 0.14254024624824524\n",
      "Accuracy on validation set: 0.9741\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.012855786830186844\n",
      "Accuracy on training set: 0.9955800000000001\n",
      "\n",
      "Validation loss: 0.15819023549556732\n",
      "Accuracy on validation set: 0.9717\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.012194188311696053\n",
      "Accuracy on training set: 0.9954400000000001\n",
      "\n",
      "Validation loss: 0.14839984476566315\n",
      "Accuracy on validation set: 0.9726\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.01540383044630289\n",
      "Accuracy on training set: 0.9948400000000002\n",
      "\n",
      "Validation loss: 0.15027113258838654\n",
      "Accuracy on validation set: 0.9718\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.011735355481505394\n",
      "Accuracy on training set: 0.9959600000000001\n",
      "\n",
      "Validation loss: 0.1455356627702713\n",
      "Accuracy on validation set: 0.9772\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.01341900136321783\n",
      "Accuracy on training set: 0.9954000000000001\n",
      "\n",
      "Validation loss: 0.14882537722587585\n",
      "Accuracy on validation set: 0.974\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.010700819082558155\n",
      "Accuracy on training set: 0.99614\n",
      "\n",
      "Validation loss: 0.15779657661914825\n",
      "Accuracy on validation set: 0.9741\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.010317209176719189\n",
      "Accuracy on training set: 0.99668\n",
      "\n",
      "Validation loss: 0.15342731773853302\n",
      "Accuracy on validation set: 0.975\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.15342731773853302\n",
      "Final accuracy on validation set: 0.975\n",
      "\n",
      "\n",
      "##### MODEL: 20/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.4541126787662506\n",
      "Accuracy on training set: 0.8669600000000001\n",
      "\n",
      "Validation loss: 0.2017417997121811\n",
      "Accuracy on validation set: 0.9399\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.25945812463760376\n",
      "Accuracy on training set: 0.9256\n",
      "\n",
      "Validation loss: 0.15920084714889526\n",
      "Accuracy on validation set: 0.9517\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.21891459822654724\n",
      "Accuracy on training set: 0.93574\n",
      "\n",
      "Validation loss: 0.15599438548088074\n",
      "Accuracy on validation set: 0.9519\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.2001420110464096\n",
      "Accuracy on training set: 0.9416800000000001\n",
      "\n",
      "Validation loss: 0.13509923219680786\n",
      "Accuracy on validation set: 0.9592\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.1873881220817566\n",
      "Accuracy on training set: 0.94496\n",
      "\n",
      "Validation loss: 0.1251291185617447\n",
      "Accuracy on validation set: 0.9624\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.17787359654903412\n",
      "Accuracy on training set: 0.94794\n",
      "\n",
      "Validation loss: 0.12465135753154755\n",
      "Accuracy on validation set: 0.9615\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.17137259244918823\n",
      "Accuracy on training set: 0.95096\n",
      "\n",
      "Validation loss: 0.12155736237764359\n",
      "Accuracy on validation set: 0.9627\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.1618923842906952\n",
      "Accuracy on training set: 0.952\n",
      "\n",
      "Validation loss: 0.12191493809223175\n",
      "Accuracy on validation set: 0.9638\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.15796369314193726\n",
      "Accuracy on training set: 0.95386\n",
      "\n",
      "Validation loss: 0.11930904537439346\n",
      "Accuracy on validation set: 0.9643\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.15261900424957275\n",
      "Accuracy on training set: 0.9552\n",
      "\n",
      "Validation loss: 0.11881405115127563\n",
      "Accuracy on validation set: 0.965\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.14570318162441254\n",
      "Accuracy on training set: 0.9577400000000001\n",
      "\n",
      "Validation loss: 0.1060815081000328\n",
      "Accuracy on validation set: 0.9699\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.14376159012317657\n",
      "Accuracy on training set: 0.95684\n",
      "\n",
      "Validation loss: 0.10931716114282608\n",
      "Accuracy on validation set: 0.968\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.1390581578016281\n",
      "Accuracy on training set: 0.95858\n",
      "\n",
      "Validation loss: 0.10222452878952026\n",
      "Accuracy on validation set: 0.9686\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.1369190812110901\n",
      "Accuracy on training set: 0.96018\n",
      "\n",
      "Validation loss: 0.11526791006326675\n",
      "Accuracy on validation set: 0.9684\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.13155798614025116\n",
      "Accuracy on training set: 0.9613800000000001\n",
      "\n",
      "Validation loss: 0.10527870804071426\n",
      "Accuracy on validation set: 0.9695\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.1325167566537857\n",
      "Accuracy on training set: 0.9622600000000001\n",
      "\n",
      "Validation loss: 0.1068982183933258\n",
      "Accuracy on validation set: 0.9701\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.12876252830028534\n",
      "Accuracy on training set: 0.96196\n",
      "\n",
      "Validation loss: 0.10387996584177017\n",
      "Accuracy on validation set: 0.9712\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.12608769536018372\n",
      "Accuracy on training set: 0.9624400000000001\n",
      "\n",
      "Validation loss: 0.10103908181190491\n",
      "Accuracy on validation set: 0.9695\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.12265105545520782\n",
      "Accuracy on training set: 0.9631200000000001\n",
      "\n",
      "Validation loss: 0.10823072493076324\n",
      "Accuracy on validation set: 0.9692\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.12419288605451584\n",
      "Accuracy on training set: 0.9633200000000001\n",
      "\n",
      "Validation loss: 0.10727997124195099\n",
      "Accuracy on validation set: 0.968\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.12164203077554703\n",
      "Accuracy on training set: 0.9639200000000001\n",
      "\n",
      "Validation loss: 0.11119471490383148\n",
      "Accuracy on validation set: 0.9676\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.11940474063158035\n",
      "Accuracy on training set: 0.9646600000000001\n",
      "\n",
      "Validation loss: 0.10969994962215424\n",
      "Accuracy on validation set: 0.9682\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.11832814663648605\n",
      "Accuracy on training set: 0.96376\n",
      "\n",
      "Validation loss: 0.11265905946493149\n",
      "Accuracy on validation set: 0.9678\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.11706256866455078\n",
      "Accuracy on training set: 0.9659800000000001\n",
      "\n",
      "Validation loss: 0.12153686583042145\n",
      "Accuracy on validation set: 0.9666\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.1174284815788269\n",
      "Accuracy on training set: 0.96472\n",
      "\n",
      "Validation loss: 0.1091044470667839\n",
      "Accuracy on validation set: 0.9694\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.11907228082418442\n",
      "Accuracy on training set: 0.9661600000000001\n",
      "\n",
      "Validation loss: 0.10728850960731506\n",
      "Accuracy on validation set: 0.9697\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.11506374925374985\n",
      "Accuracy on training set: 0.96572\n",
      "\n",
      "Validation loss: 0.11496225744485855\n",
      "Accuracy on validation set: 0.9688\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.11129492521286011\n",
      "Accuracy on training set: 0.9676000000000001\n",
      "\n",
      "Validation loss: 0.11673376709222794\n",
      "Accuracy on validation set: 0.9695\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.10747862607240677\n",
      "Accuracy on training set: 0.9683600000000001\n",
      "\n",
      "Validation loss: 0.10574939101934433\n",
      "Accuracy on validation set: 0.9712\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.11237163096666336\n",
      "Accuracy on training set: 0.966\n",
      "\n",
      "Validation loss: 0.10632061958312988\n",
      "Accuracy on validation set: 0.9702\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.10632061958312988\n",
      "Final accuracy on validation set: 0.9702\n",
      "\n",
      "\n",
      "##### MODEL: 21/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0.001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.7347911596298218\n",
      "Accuracy on training set: 0.81124\n",
      "\n",
      "Validation loss: 0.40219542384147644\n",
      "Accuracy on validation set: 0.8932\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.3535490334033966\n",
      "Accuracy on training set: 0.90538\n",
      "\n",
      "Validation loss: 0.3222063481807709\n",
      "Accuracy on validation set: 0.9153\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.29884031414985657\n",
      "Accuracy on training set: 0.9203600000000001\n",
      "\n",
      "Validation loss: 0.2920900285243988\n",
      "Accuracy on validation set: 0.922\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.268097847700119\n",
      "Accuracy on training set: 0.92872\n",
      "\n",
      "Validation loss: 0.2549622654914856\n",
      "Accuracy on validation set: 0.9329\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.24727606773376465\n",
      "Accuracy on training set: 0.93438\n",
      "\n",
      "Validation loss: 0.2415388971567154\n",
      "Accuracy on validation set: 0.9394\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.23475395143032074\n",
      "Accuracy on training set: 0.93878\n",
      "\n",
      "Validation loss: 0.2300657033920288\n",
      "Accuracy on validation set: 0.9401\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.2258511185646057\n",
      "Accuracy on training set: 0.94048\n",
      "\n",
      "Validation loss: 0.22866982221603394\n",
      "Accuracy on validation set: 0.9392\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.21873028576374054\n",
      "Accuracy on training set: 0.9428399999999999\n",
      "\n",
      "Validation loss: 0.22123220562934875\n",
      "Accuracy on validation set: 0.9413\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.21375437080860138\n",
      "Accuracy on training set: 0.94434\n",
      "\n",
      "Validation loss: 0.22217033803462982\n",
      "Accuracy on validation set: 0.9385\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.2105783075094223\n",
      "Accuracy on training set: 0.945\n",
      "\n",
      "Validation loss: 0.21281655132770538\n",
      "Accuracy on validation set: 0.9432\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.2062857449054718\n",
      "Accuracy on training set: 0.9458\n",
      "\n",
      "Validation loss: 0.21133923530578613\n",
      "Accuracy on validation set: 0.9444\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.20505593717098236\n",
      "Accuracy on training set: 0.94648\n",
      "\n",
      "Validation loss: 0.2122877687215805\n",
      "Accuracy on validation set: 0.9441\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.20318768918514252\n",
      "Accuracy on training set: 0.94712\n",
      "\n",
      "Validation loss: 0.21155141294002533\n",
      "Accuracy on validation set: 0.9454\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.20132318139076233\n",
      "Accuracy on training set: 0.9472\n",
      "\n",
      "Validation loss: 0.20660163462162018\n",
      "Accuracy on validation set: 0.948\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.19989794492721558\n",
      "Accuracy on training set: 0.94852\n",
      "\n",
      "Validation loss: 0.20948576927185059\n",
      "Accuracy on validation set: 0.9446\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.19903045892715454\n",
      "Accuracy on training set: 0.9486\n",
      "\n",
      "Validation loss: 0.20281097292900085\n",
      "Accuracy on validation set: 0.9458\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.19787634909152985\n",
      "Accuracy on training set: 0.94942\n",
      "\n",
      "Validation loss: 0.20839808881282806\n",
      "Accuracy on validation set: 0.9465\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.19781048595905304\n",
      "Accuracy on training set: 0.9492\n",
      "\n",
      "Validation loss: 0.2222781777381897\n",
      "Accuracy on validation set: 0.9369\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.1968950480222702\n",
      "Accuracy on training set: 0.94856\n",
      "\n",
      "Validation loss: 0.20884811878204346\n",
      "Accuracy on validation set: 0.9427\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.19652605056762695\n",
      "Accuracy on training set: 0.94964\n",
      "\n",
      "Validation loss: 0.20935605466365814\n",
      "Accuracy on validation set: 0.945\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.1951252967119217\n",
      "Accuracy on training set: 0.9498199999999999\n",
      "\n",
      "Validation loss: 0.19761647284030914\n",
      "Accuracy on validation set: 0.949\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.19525663554668427\n",
      "Accuracy on training set: 0.94952\n",
      "\n",
      "Validation loss: 0.2022681087255478\n",
      "Accuracy on validation set: 0.9463\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.19454631209373474\n",
      "Accuracy on training set: 0.9502\n",
      "\n",
      "Validation loss: 0.21174319088459015\n",
      "Accuracy on validation set: 0.9459\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.19367606937885284\n",
      "Accuracy on training set: 0.95062\n",
      "\n",
      "Validation loss: 0.20084503293037415\n",
      "Accuracy on validation set: 0.9463\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.19345158338546753\n",
      "Accuracy on training set: 0.95052\n",
      "\n",
      "Validation loss: 0.20193342864513397\n",
      "Accuracy on validation set: 0.9484\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.1923966109752655\n",
      "Accuracy on training set: 0.95066\n",
      "\n",
      "Validation loss: 0.20624157786369324\n",
      "Accuracy on validation set: 0.9459\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.19266647100448608\n",
      "Accuracy on training set: 0.95074\n",
      "\n",
      "Validation loss: 0.19834889471530914\n",
      "Accuracy on validation set: 0.9504\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.1929723024368286\n",
      "Accuracy on training set: 0.9501799999999999\n",
      "\n",
      "Validation loss: 0.19979162514209747\n",
      "Accuracy on validation set: 0.9459\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.19245505332946777\n",
      "Accuracy on training set: 0.94962\n",
      "\n",
      "Validation loss: 0.19990336894989014\n",
      "Accuracy on validation set: 0.9456\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.19201654195785522\n",
      "Accuracy on training set: 0.95064\n",
      "\n",
      "Validation loss: 0.1982191652059555\n",
      "Accuracy on validation set: 0.9481\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.1982191652059555\n",
      "Final accuracy on validation set: 0.9481\n",
      "\n",
      "\n",
      "##### MODEL: 22/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0.001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0, 'Act_func': ReLU()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.3400677740573883\n",
      "Accuracy on training set: 0.89822\n",
      "\n",
      "Validation loss: 0.22227509319782257\n",
      "Accuracy on validation set: 0.93\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.19104428589344025\n",
      "Accuracy on training set: 0.94108\n",
      "\n",
      "Validation loss: 0.16409264504909515\n",
      "Accuracy on validation set: 0.951\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.17321975529193878\n",
      "Accuracy on training set: 0.94812\n",
      "\n",
      "Validation loss: 0.2426874339580536\n",
      "Accuracy on validation set: 0.9279\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.1625148057937622\n",
      "Accuracy on training set: 0.9492\n",
      "\n",
      "Validation loss: 0.15535637736320496\n",
      "Accuracy on validation set: 0.9534\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.15876999497413635\n",
      "Accuracy on training set: 0.9504600000000001\n",
      "\n",
      "Validation loss: 0.15085965394973755\n",
      "Accuracy on validation set: 0.9538\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.15677648782730103\n",
      "Accuracy on training set: 0.9517599999999999\n",
      "\n",
      "Validation loss: 0.16754306852817535\n",
      "Accuracy on validation set: 0.95\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.1562938243150711\n",
      "Accuracy on training set: 0.9529000000000001\n",
      "\n",
      "Validation loss: 0.1534595638513565\n",
      "Accuracy on validation set: 0.9513\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.1509539783000946\n",
      "Accuracy on training set: 0.95352\n",
      "\n",
      "Validation loss: 0.13985620439052582\n",
      "Accuracy on validation set: 0.9571\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.1535748392343521\n",
      "Accuracy on training set: 0.95294\n",
      "\n",
      "Validation loss: 0.1822197288274765\n",
      "Accuracy on validation set: 0.9438\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.15071947872638702\n",
      "Accuracy on training set: 0.95382\n",
      "\n",
      "Validation loss: 0.21836484968662262\n",
      "Accuracy on validation set: 0.9366\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.14812517166137695\n",
      "Accuracy on training set: 0.95452\n",
      "\n",
      "Validation loss: 0.14556501805782318\n",
      "Accuracy on validation set: 0.9552\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.15160031616687775\n",
      "Accuracy on training set: 0.9545800000000002\n",
      "\n",
      "Validation loss: 0.13364604115486145\n",
      "Accuracy on validation set: 0.9596\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.14957763254642487\n",
      "Accuracy on training set: 0.9549200000000001\n",
      "\n",
      "Validation loss: 0.16138184070587158\n",
      "Accuracy on validation set: 0.9509\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.1491343379020691\n",
      "Accuracy on training set: 0.9535\n",
      "\n",
      "Validation loss: 0.15396377444267273\n",
      "Accuracy on validation set: 0.9546\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.14859160780906677\n",
      "Accuracy on training set: 0.954\n",
      "\n",
      "Validation loss: 0.1368561089038849\n",
      "Accuracy on validation set: 0.9584\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.14729923009872437\n",
      "Accuracy on training set: 0.9551000000000001\n",
      "\n",
      "Validation loss: 0.13429155945777893\n",
      "Accuracy on validation set: 0.9589\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.14854757487773895\n",
      "Accuracy on training set: 0.95474\n",
      "\n",
      "Validation loss: 0.15750785171985626\n",
      "Accuracy on validation set: 0.9522\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.1492932140827179\n",
      "Accuracy on training set: 0.9545399999999999\n",
      "\n",
      "Validation loss: 0.18132516741752625\n",
      "Accuracy on validation set: 0.9459\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.1446257084608078\n",
      "Accuracy on training set: 0.9546\n",
      "\n",
      "Validation loss: 0.18719741702079773\n",
      "Accuracy on validation set: 0.944\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.14834243059158325\n",
      "Accuracy on training set: 0.9545799999999999\n",
      "\n",
      "Validation loss: 0.14844512939453125\n",
      "Accuracy on validation set: 0.9569\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.14800246059894562\n",
      "Accuracy on training set: 0.95474\n",
      "\n",
      "Validation loss: 0.1558377742767334\n",
      "Accuracy on validation set: 0.9522\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.14704406261444092\n",
      "Accuracy on training set: 0.9553400000000001\n",
      "\n",
      "Validation loss: 0.15561766922473907\n",
      "Accuracy on validation set: 0.9527\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.1471458077430725\n",
      "Accuracy on training set: 0.95598\n",
      "\n",
      "Validation loss: 0.22028139233589172\n",
      "Accuracy on validation set: 0.9348\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.1460038423538208\n",
      "Accuracy on training set: 0.955\n",
      "\n",
      "Validation loss: 0.15657581388950348\n",
      "Accuracy on validation set: 0.953\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.14632846415042877\n",
      "Accuracy on training set: 0.9541000000000002\n",
      "\n",
      "Validation loss: 0.16927947103977203\n",
      "Accuracy on validation set: 0.9498\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.1477135866880417\n",
      "Accuracy on training set: 0.9548\n",
      "\n",
      "Validation loss: 0.15672051906585693\n",
      "Accuracy on validation set: 0.9534\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.1443144977092743\n",
      "Accuracy on training set: 0.9556800000000001\n",
      "\n",
      "Validation loss: 0.1344800889492035\n",
      "Accuracy on validation set: 0.9595\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.14512400329113007\n",
      "Accuracy on training set: 0.95524\n",
      "\n",
      "Validation loss: 0.1310562938451767\n",
      "Accuracy on validation set: 0.96\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.14568907022476196\n",
      "Accuracy on training set: 0.95442\n",
      "\n",
      "Validation loss: 0.16027207672595978\n",
      "Accuracy on validation set: 0.949\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.14470422267913818\n",
      "Accuracy on training set: 0.95548\n",
      "\n",
      "Validation loss: 0.24439020454883575\n",
      "Accuracy on validation set: 0.9219\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.24439020454883575\n",
      "Final accuracy on validation set: 0.9219\n",
      "\n",
      "\n",
      "##### MODEL: 23/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0.0001, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.4868968427181244\n",
      "Accuracy on training set: 0.86446\n",
      "\n",
      "Validation loss: 0.2689485549926758\n",
      "Accuracy on validation set: 0.9204\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.22306610643863678\n",
      "Accuracy on training set: 0.93452\n",
      "\n",
      "Validation loss: 0.19724276661872864\n",
      "Accuracy on validation set: 0.9434\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.16710658371448517\n",
      "Accuracy on training set: 0.95096\n",
      "\n",
      "Validation loss: 0.1711723804473877\n",
      "Accuracy on validation set: 0.9492\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.13517069816589355\n",
      "Accuracy on training set: 0.95982\n",
      "\n",
      "Validation loss: 0.13572698831558228\n",
      "Accuracy on validation set: 0.9602\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.11415298283100128\n",
      "Accuracy on training set: 0.9661200000000001\n",
      "\n",
      "Validation loss: 0.1195797473192215\n",
      "Accuracy on validation set: 0.9651\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.09976638108491898\n",
      "Accuracy on training set: 0.9710200000000001\n",
      "\n",
      "Validation loss: 0.11359525471925735\n",
      "Accuracy on validation set: 0.9657\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.08914880454540253\n",
      "Accuracy on training set: 0.9739000000000001\n",
      "\n",
      "Validation loss: 0.11018989235162735\n",
      "Accuracy on validation set: 0.9668\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.08048153668642044\n",
      "Accuracy on training set: 0.9767600000000001\n",
      "\n",
      "Validation loss: 0.1053621917963028\n",
      "Accuracy on validation set: 0.9682\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.0737331435084343\n",
      "Accuracy on training set: 0.9790000000000001\n",
      "\n",
      "Validation loss: 0.10197613388299942\n",
      "Accuracy on validation set: 0.9688\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.06804925203323364\n",
      "Accuracy on training set: 0.9802800000000002\n",
      "\n",
      "Validation loss: 0.10100813955068588\n",
      "Accuracy on validation set: 0.9704\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.06296218931674957\n",
      "Accuracy on training set: 0.9821\n",
      "\n",
      "Validation loss: 0.08910281211137772\n",
      "Accuracy on validation set: 0.9737\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.0599435530602932\n",
      "Accuracy on training set: 0.9830800000000002\n",
      "\n",
      "Validation loss: 0.09614384919404984\n",
      "Accuracy on validation set: 0.97\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.05600965768098831\n",
      "Accuracy on training set: 0.98406\n",
      "\n",
      "Validation loss: 0.09581778198480606\n",
      "Accuracy on validation set: 0.9713\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.05372457578778267\n",
      "Accuracy on training set: 0.9853600000000001\n",
      "\n",
      "Validation loss: 0.08604311943054199\n",
      "Accuracy on validation set: 0.9752\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.0513719879090786\n",
      "Accuracy on training set: 0.98524\n",
      "\n",
      "Validation loss: 0.08473551273345947\n",
      "Accuracy on validation set: 0.9741\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.04844328388571739\n",
      "Accuracy on training set: 0.9865800000000001\n",
      "\n",
      "Validation loss: 0.0857565626502037\n",
      "Accuracy on validation set: 0.9738\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.04745608568191528\n",
      "Accuracy on training set: 0.9866200000000002\n",
      "\n",
      "Validation loss: 0.09141479432582855\n",
      "Accuracy on validation set: 0.9729\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.0463271327316761\n",
      "Accuracy on training set: 0.9868000000000001\n",
      "\n",
      "Validation loss: 0.09597775340080261\n",
      "Accuracy on validation set: 0.9697\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.04409974068403244\n",
      "Accuracy on training set: 0.9877400000000001\n",
      "\n",
      "Validation loss: 0.07901044189929962\n",
      "Accuracy on validation set: 0.9743\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.043299492448568344\n",
      "Accuracy on training set: 0.9876800000000001\n",
      "\n",
      "Validation loss: 0.07809032499790192\n",
      "Accuracy on validation set: 0.9757\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.04256095737218857\n",
      "Accuracy on training set: 0.9878800000000001\n",
      "\n",
      "Validation loss: 0.08128134906291962\n",
      "Accuracy on validation set: 0.9739\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.04034708812832832\n",
      "Accuracy on training set: 0.9896000000000001\n",
      "\n",
      "Validation loss: 0.07977137714624405\n",
      "Accuracy on validation set: 0.9751\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.04071243852376938\n",
      "Accuracy on training set: 0.9890800000000001\n",
      "\n",
      "Validation loss: 0.08650343865156174\n",
      "Accuracy on validation set: 0.9734\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.03969992324709892\n",
      "Accuracy on training set: 0.9889600000000001\n",
      "\n",
      "Validation loss: 0.07520398497581482\n",
      "Accuracy on validation set: 0.978\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.038654349744319916\n",
      "Accuracy on training set: 0.9895400000000001\n",
      "\n",
      "Validation loss: 0.07886619120836258\n",
      "Accuracy on validation set: 0.978\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.038470763713121414\n",
      "Accuracy on training set: 0.98948\n",
      "\n",
      "Validation loss: 0.08332371711730957\n",
      "Accuracy on validation set: 0.9753\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.038068242371082306\n",
      "Accuracy on training set: 0.9895600000000001\n",
      "\n",
      "Validation loss: 0.08165690302848816\n",
      "Accuracy on validation set: 0.9756\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.037852104753255844\n",
      "Accuracy on training set: 0.9895400000000001\n",
      "\n",
      "Validation loss: 0.07368170469999313\n",
      "Accuracy on validation set: 0.9772\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.03660373017191887\n",
      "Accuracy on training set: 0.9898\n",
      "\n",
      "Validation loss: 0.07311280816793442\n",
      "Accuracy on validation set: 0.9781\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.03607702627778053\n",
      "Accuracy on training set: 0.9900800000000002\n",
      "\n",
      "Validation loss: 0.07431115955114365\n",
      "Accuracy on validation set: 0.9774\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.07431115955114365\n",
      "Final accuracy on validation set: 0.9774\n",
      "\n",
      "\n",
      "##### MODEL: 24/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.005, 'Regularizer_L2': 0.0001, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.4275108277797699\n",
      "Accuracy on training set: 0.86924\n",
      "\n",
      "Validation loss: 0.19674955308437347\n",
      "Accuracy on validation set: 0.9384\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.22450827062129974\n",
      "Accuracy on training set: 0.93248\n",
      "\n",
      "Validation loss: 0.15300190448760986\n",
      "Accuracy on validation set: 0.9523\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.19578683376312256\n",
      "Accuracy on training set: 0.94044\n",
      "\n",
      "Validation loss: 0.12761080265045166\n",
      "Accuracy on validation set: 0.9612\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.18843881785869598\n",
      "Accuracy on training set: 0.94214\n",
      "\n",
      "Validation loss: 0.12052217125892639\n",
      "Accuracy on validation set: 0.9625\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.17340610921382904\n",
      "Accuracy on training set: 0.94696\n",
      "\n",
      "Validation loss: 0.12314528971910477\n",
      "Accuracy on validation set: 0.9625\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.1750987470149994\n",
      "Accuracy on training set: 0.9462999999999999\n",
      "\n",
      "Validation loss: 0.12852895259857178\n",
      "Accuracy on validation set: 0.9604\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.17247484624385834\n",
      "Accuracy on training set: 0.94758\n",
      "\n",
      "Validation loss: 0.11654689908027649\n",
      "Accuracy on validation set: 0.9641\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.16814956068992615\n",
      "Accuracy on training set: 0.94808\n",
      "\n",
      "Validation loss: 0.10598746687173843\n",
      "Accuracy on validation set: 0.9687\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.16631600260734558\n",
      "Accuracy on training set: 0.9490999999999999\n",
      "\n",
      "Validation loss: 0.12476667761802673\n",
      "Accuracy on validation set: 0.9638\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.16602176427841187\n",
      "Accuracy on training set: 0.9468000000000001\n",
      "\n",
      "Validation loss: 0.11752665787935257\n",
      "Accuracy on validation set: 0.9642\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.16111360490322113\n",
      "Accuracy on training set: 0.94934\n",
      "\n",
      "Validation loss: 0.11761119216680527\n",
      "Accuracy on validation set: 0.9653\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.1641373485326767\n",
      "Accuracy on training set: 0.94926\n",
      "\n",
      "Validation loss: 0.11100943386554718\n",
      "Accuracy on validation set: 0.9667\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.1620444655418396\n",
      "Accuracy on training set: 0.9495399999999999\n",
      "\n",
      "Validation loss: 0.11464075744152069\n",
      "Accuracy on validation set: 0.9654\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.1617889404296875\n",
      "Accuracy on training set: 0.9499200000000001\n",
      "\n",
      "Validation loss: 0.10208936780691147\n",
      "Accuracy on validation set: 0.9686\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.15906348824501038\n",
      "Accuracy on training set: 0.95002\n",
      "\n",
      "Validation loss: 0.1221621185541153\n",
      "Accuracy on validation set: 0.9631\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.16236242651939392\n",
      "Accuracy on training set: 0.95074\n",
      "\n",
      "Validation loss: 0.10777585208415985\n",
      "Accuracy on validation set: 0.9666\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.16161687672138214\n",
      "Accuracy on training set: 0.9500599999999999\n",
      "\n",
      "Validation loss: 0.1284150332212448\n",
      "Accuracy on validation set: 0.9615\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.15915939211845398\n",
      "Accuracy on training set: 0.9511400000000001\n",
      "\n",
      "Validation loss: 0.11321273446083069\n",
      "Accuracy on validation set: 0.9658\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.1607351452112198\n",
      "Accuracy on training set: 0.9494400000000001\n",
      "\n",
      "Validation loss: 0.10587228089570999\n",
      "Accuracy on validation set: 0.9677\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.1615474373102188\n",
      "Accuracy on training set: 0.9495\n",
      "\n",
      "Validation loss: 0.10835368931293488\n",
      "Accuracy on validation set: 0.9669\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.1634599268436432\n",
      "Accuracy on training set: 0.94988\n",
      "\n",
      "Validation loss: 0.10469527542591095\n",
      "Accuracy on validation set: 0.968\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.1593400090932846\n",
      "Accuracy on training set: 0.95012\n",
      "\n",
      "Validation loss: 0.10931182652711868\n",
      "Accuracy on validation set: 0.9668\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.16342492401599884\n",
      "Accuracy on training set: 0.9486600000000001\n",
      "\n",
      "Validation loss: 0.10704006254673004\n",
      "Accuracy on validation set: 0.9657\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.16149090230464935\n",
      "Accuracy on training set: 0.9489000000000001\n",
      "\n",
      "Validation loss: 0.10807295143604279\n",
      "Accuracy on validation set: 0.9667\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.15891580283641815\n",
      "Accuracy on training set: 0.95128\n",
      "\n",
      "Validation loss: 0.1119176372885704\n",
      "Accuracy on validation set: 0.9652\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.15865810215473175\n",
      "Accuracy on training set: 0.95082\n",
      "\n",
      "Validation loss: 0.1091802716255188\n",
      "Accuracy on validation set: 0.967\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.15728747844696045\n",
      "Accuracy on training set: 0.9511999999999999\n",
      "\n",
      "Validation loss: 0.11194559186697006\n",
      "Accuracy on validation set: 0.9676\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.15666545927524567\n",
      "Accuracy on training set: 0.95058\n",
      "\n",
      "Validation loss: 0.1145184338092804\n",
      "Accuracy on validation set: 0.9642\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.15890346467494965\n",
      "Accuracy on training set: 0.9519000000000001\n",
      "\n",
      "Validation loss: 0.13000352680683136\n",
      "Accuracy on validation set: 0.9597\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.15846523642539978\n",
      "Accuracy on training set: 0.95188\n",
      "\n",
      "Validation loss: 0.10169046372175217\n",
      "Accuracy on validation set: 0.9694\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.10169046372175217\n",
      "Final accuracy on validation set: 0.9694\n",
      "\n",
      "\n",
      "##### MODEL: 25/25 #####\n",
      "\n",
      "\n",
      "Hyperparameters combination:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0.0001, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 64, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': Sigmoid()}\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 1.0554200410842896\n",
      "Accuracy on training set: 0.6870999999999999\n",
      "\n",
      "Validation loss: 0.42539000511169434\n",
      "Accuracy on validation set: 0.8885\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.45805424451828003\n",
      "Accuracy on training set: 0.8718800000000001\n",
      "\n",
      "Validation loss: 0.30568090081214905\n",
      "Accuracy on validation set: 0.9136\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.37473493814468384\n",
      "Accuracy on training set: 0.89228\n",
      "\n",
      "Validation loss: 0.25599563121795654\n",
      "Accuracy on validation set: 0.9263\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.33096179366111755\n",
      "Accuracy on training set: 0.9057000000000001\n",
      "\n",
      "Validation loss: 0.22439908981323242\n",
      "Accuracy on validation set: 0.9338\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.30477067828178406\n",
      "Accuracy on training set: 0.9100800000000001\n",
      "\n",
      "Validation loss: 0.2017635852098465\n",
      "Accuracy on validation set: 0.9399\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.2867036759853363\n",
      "Accuracy on training set: 0.91586\n",
      "\n",
      "Validation loss: 0.18380199372768402\n",
      "Accuracy on validation set: 0.9456\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.27018916606903076\n",
      "Accuracy on training set: 0.9210400000000001\n",
      "\n",
      "Validation loss: 0.17304103076457977\n",
      "Accuracy on validation set: 0.9479\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.2579144239425659\n",
      "Accuracy on training set: 0.9243800000000001\n",
      "\n",
      "Validation loss: 0.16391496360301971\n",
      "Accuracy on validation set: 0.9508\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.24831180274486542\n",
      "Accuracy on training set: 0.92708\n",
      "\n",
      "Validation loss: 0.15744204819202423\n",
      "Accuracy on validation set: 0.9516\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.2387162446975708\n",
      "Accuracy on training set: 0.9281800000000001\n",
      "\n",
      "Validation loss: 0.15717734396457672\n",
      "Accuracy on validation set: 0.9521\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.23318883776664734\n",
      "Accuracy on training set: 0.92964\n",
      "\n",
      "Validation loss: 0.14736244082450867\n",
      "Accuracy on validation set: 0.9528\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.22611618041992188\n",
      "Accuracy on training set: 0.9332\n",
      "\n",
      "Validation loss: 0.14174599945545197\n",
      "Accuracy on validation set: 0.9549\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.2209380567073822\n",
      "Accuracy on training set: 0.93342\n",
      "\n",
      "Validation loss: 0.136566624045372\n",
      "Accuracy on validation set: 0.9577\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.21963638067245483\n",
      "Accuracy on training set: 0.9335399999999999\n",
      "\n",
      "Validation loss: 0.13528895378112793\n",
      "Accuracy on validation set: 0.9581\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.21444253623485565\n",
      "Accuracy on training set: 0.9359200000000001\n",
      "\n",
      "Validation loss: 0.13226436078548431\n",
      "Accuracy on validation set: 0.9594\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.2112327218055725\n",
      "Accuracy on training set: 0.9361799999999999\n",
      "\n",
      "Validation loss: 0.12969514727592468\n",
      "Accuracy on validation set: 0.9598\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.20804694294929504\n",
      "Accuracy on training set: 0.93574\n",
      "\n",
      "Validation loss: 0.13013482093811035\n",
      "Accuracy on validation set: 0.9598\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.20747315883636475\n",
      "Accuracy on training set: 0.9365999999999999\n",
      "\n",
      "Validation loss: 0.12699589133262634\n",
      "Accuracy on validation set: 0.9603\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.202015221118927\n",
      "Accuracy on training set: 0.9388\n",
      "\n",
      "Validation loss: 0.12487950176000595\n",
      "Accuracy on validation set: 0.9614\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.20234592258930206\n",
      "Accuracy on training set: 0.93884\n",
      "\n",
      "Validation loss: 0.1255965381860733\n",
      "Accuracy on validation set: 0.961\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.19711406528949738\n",
      "Accuracy on training set: 0.9399200000000001\n",
      "\n",
      "Validation loss: 0.122818224132061\n",
      "Accuracy on validation set: 0.9622\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.19577819108963013\n",
      "Accuracy on training set: 0.9411\n",
      "\n",
      "Validation loss: 0.12095745652914047\n",
      "Accuracy on validation set: 0.9629\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.19223247468471527\n",
      "Accuracy on training set: 0.9411200000000001\n",
      "\n",
      "Validation loss: 0.12398175150156021\n",
      "Accuracy on validation set: 0.9613\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.19583700597286224\n",
      "Accuracy on training set: 0.94104\n",
      "\n",
      "Validation loss: 0.11799086630344391\n",
      "Accuracy on validation set: 0.9644\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.19226181507110596\n",
      "Accuracy on training set: 0.9422200000000001\n",
      "\n",
      "Validation loss: 0.11811742931604385\n",
      "Accuracy on validation set: 0.9626\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.19177645444869995\n",
      "Accuracy on training set: 0.9420599999999999\n",
      "\n",
      "Validation loss: 0.11615410447120667\n",
      "Accuracy on validation set: 0.9639\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.19556188583374023\n",
      "Accuracy on training set: 0.94098\n",
      "\n",
      "Validation loss: 0.11714864522218704\n",
      "Accuracy on validation set: 0.9644\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.18928690254688263\n",
      "Accuracy on training set: 0.9419200000000001\n",
      "\n",
      "Validation loss: 0.11764826625585556\n",
      "Accuracy on validation set: 0.9633\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.18858127295970917\n",
      "Accuracy on training set: 0.942\n",
      "\n",
      "Validation loss: 0.11451034247875214\n",
      "Accuracy on validation set: 0.9644\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.18623200058937073\n",
      "Accuracy on training set: 0.9428800000000002\n",
      "\n",
      "Validation loss: 0.11239223927259445\n",
      "Accuracy on validation set: 0.9661\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "Final loss on validation set: 0.11239223927259445\n",
      "Final accuracy on validation set: 0.9661\n"
     ]
    }
   ],
   "source": [
    "# Sampling\n",
    "from random import sample\n",
    "torch.manual_seed(0)\n",
    "samples = 25 # Number of samples (models) for random search\n",
    "random_indeces = sample(range(0, len(combinations_dict)), samples) # Indeces to sample random combinations \n",
    "random_combinations_FFNN = [] # List of random combinations\n",
    "\n",
    "for random_ind in random_indeces:\n",
    "  random_combinations_FFNN.append(combinations_dict[random_ind])\n",
    "\n",
    "scores_hyperpar_FFNN_models = [] # List of tuples with the score of the model and the set of hyperparameters for that score\n",
    "number_combinations = len(random_combinations_FFNN) # Number of the all combinations\n",
    "model_number = 1 # Counter for the grid search\n",
    "FFNN_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for hyperparam_combination in random_combinations_FFNN:\n",
    "\n",
    "  FFNN = Net(784, hyperparam_combination[\"Num_hidd_neurons\"], hyperparam_combination[\"Num_hidd_neurons\"], 10, hyperparam_combination[\"Act_func\"], hyperparam_combination[\"Dropout\"])\n",
    "  FFNN_device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # Check if the GPU is available\n",
    "  FFNN.to(FFNN_device)\n",
    "  optimizer = hyperparam_combination[\"Optimizer\"](FFNN.parameters(), hyperparam_combination[\"lr\"], weight_decay = hyperparam_combination[\"Regularizer_L2\"])\n",
    "  num_epochs = hyperparam_combination[\"Epochs\"]\n",
    "\n",
    "  print(f\"\\n\\n##### MODEL: {model_number}/{number_combinations} #####\\n\")\n",
    "  print(\"\\nHyperparameters combination:\\n\", hyperparam_combination)\n",
    "  model_number += 1\n",
    "  train_loss, accuracy_train_scores, validation_loss, accuracy_val_scores = train_function_FFNN(FFNN, train_dataloader_new, validation_dataloader, num_epochs, optimizer, FFNN_loss)\n",
    "  print(\"\\n\\n\\nFINAL RESULT:\")\n",
    "  print(f\"Final loss on validation set: {validation_loss[-1]}\")\n",
    "  print(f\"Final accuracy on validation set: {accuracy_val_scores[-1]}\")\n",
    "\n",
    "  scores_hyperpar_FFNN_models.append((validation_loss[-1], accuracy_val_scores[-1], hyperparam_combination)) # Last validation, last accuracy and hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation and accuracy score:\n",
      " 0.074805096 0.979\n",
      "\n",
      "Best hyperparameters:\n",
      " {'lr': 0.001, 'Regularizer_L2': 0.0001, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Num_hidd_neurons': 128, 'Epochs': 30, 'Dropout': 0.3, 'Act_func': ReLU()}\n",
      "\n",
      "\n",
      "##### BEST MODEL TRAINING/TESTING #####\n",
      "\n",
      "-> Epoch 1\n",
      "\n",
      "Train loss: 0.39745354652404785\n",
      "Accuracy on training set: 0.8801166666666665\n",
      "\n",
      "Validation loss: 0.16378885507583618\n",
      "Accuracy on validation set: 0.9489\n",
      "\n",
      "-> Epoch 2\n",
      "\n",
      "Train loss: 0.1902245730161667\n",
      "Accuracy on training set: 0.94335\n",
      "\n",
      "Validation loss: 0.11308208107948303\n",
      "Accuracy on validation set: 0.967\n",
      "\n",
      "-> Epoch 3\n",
      "\n",
      "Train loss: 0.15207356214523315\n",
      "Accuracy on training set: 0.9542166666666666\n",
      "\n",
      "Validation loss: 0.10039809346199036\n",
      "Accuracy on validation set: 0.9695\n",
      "\n",
      "-> Epoch 4\n",
      "\n",
      "Train loss: 0.1297047883272171\n",
      "Accuracy on training set: 0.9603333333333334\n",
      "\n",
      "Validation loss: 0.08841131627559662\n",
      "Accuracy on validation set: 0.9736\n",
      "\n",
      "-> Epoch 5\n",
      "\n",
      "Train loss: 0.1210361197590828\n",
      "Accuracy on training set: 0.9622166666666665\n",
      "\n",
      "Validation loss: 0.0829434022307396\n",
      "Accuracy on validation set: 0.9743\n",
      "\n",
      "-> Epoch 6\n",
      "\n",
      "Train loss: 0.110863097012043\n",
      "Accuracy on training set: 0.9666666666666667\n",
      "\n",
      "Validation loss: 0.08479910343885422\n",
      "Accuracy on validation set: 0.9749\n",
      "\n",
      "-> Epoch 7\n",
      "\n",
      "Train loss: 0.10351438075304031\n",
      "Accuracy on training set: 0.9678500000000001\n",
      "\n",
      "Validation loss: 0.07845567166805267\n",
      "Accuracy on validation set: 0.976\n",
      "\n",
      "-> Epoch 8\n",
      "\n",
      "Train loss: 0.10080354660749435\n",
      "Accuracy on training set: 0.9687833333333333\n",
      "\n",
      "Validation loss: 0.08326525241136551\n",
      "Accuracy on validation set: 0.9758\n",
      "\n",
      "-> Epoch 9\n",
      "\n",
      "Train loss: 0.0945071130990982\n",
      "Accuracy on training set: 0.9708\n",
      "\n",
      "Validation loss: 0.07397904992103577\n",
      "Accuracy on validation set: 0.9776\n",
      "\n",
      "-> Epoch 10\n",
      "\n",
      "Train loss: 0.09052462130784988\n",
      "Accuracy on training set: 0.9724666666666667\n",
      "\n",
      "Validation loss: 0.07829198241233826\n",
      "Accuracy on validation set: 0.9766\n",
      "\n",
      "-> Epoch 11\n",
      "\n",
      "Train loss: 0.08802089095115662\n",
      "Accuracy on training set: 0.9722166666666665\n",
      "\n",
      "Validation loss: 0.07133768498897552\n",
      "Accuracy on validation set: 0.9786\n",
      "\n",
      "-> Epoch 12\n",
      "\n",
      "Train loss: 0.08603660017251968\n",
      "Accuracy on training set: 0.9730333333333332\n",
      "\n",
      "Validation loss: 0.07186538726091385\n",
      "Accuracy on validation set: 0.9796\n",
      "\n",
      "-> Epoch 13\n",
      "\n",
      "Train loss: 0.0843207836151123\n",
      "Accuracy on training set: 0.9741166666666667\n",
      "\n",
      "Validation loss: 0.07083108276128769\n",
      "Accuracy on validation set: 0.9779\n",
      "\n",
      "-> Epoch 14\n",
      "\n",
      "Train loss: 0.08297945559024811\n",
      "Accuracy on training set: 0.9739666666666669\n",
      "\n",
      "Validation loss: 0.06751774251461029\n",
      "Accuracy on validation set: 0.9794\n",
      "\n",
      "-> Epoch 15\n",
      "\n",
      "Train loss: 0.07893981784582138\n",
      "Accuracy on training set: 0.97555\n",
      "\n",
      "Validation loss: 0.06826803833246231\n",
      "Accuracy on validation set: 0.9803\n",
      "\n",
      "-> Epoch 16\n",
      "\n",
      "Train loss: 0.07696840912103653\n",
      "Accuracy on training set: 0.9758333333333333\n",
      "\n",
      "Validation loss: 0.06967441737651825\n",
      "Accuracy on validation set: 0.9805\n",
      "\n",
      "-> Epoch 17\n",
      "\n",
      "Train loss: 0.07637441158294678\n",
      "Accuracy on training set: 0.9752\n",
      "\n",
      "Validation loss: 0.06584405153989792\n",
      "Accuracy on validation set: 0.9815\n",
      "\n",
      "-> Epoch 18\n",
      "\n",
      "Train loss: 0.07534636557102203\n",
      "Accuracy on training set: 0.9760333333333335\n",
      "\n",
      "Validation loss: 0.06435374170541763\n",
      "Accuracy on validation set: 0.9809\n",
      "\n",
      "-> Epoch 19\n",
      "\n",
      "Train loss: 0.07388988882303238\n",
      "Accuracy on training set: 0.9760166666666666\n",
      "\n",
      "Validation loss: 0.0684308409690857\n",
      "Accuracy on validation set: 0.9805\n",
      "\n",
      "-> Epoch 20\n",
      "\n",
      "Train loss: 0.0743437111377716\n",
      "Accuracy on training set: 0.9760666666666669\n",
      "\n",
      "Validation loss: 0.06543556600809097\n",
      "Accuracy on validation set: 0.9817\n",
      "\n",
      "-> Epoch 21\n",
      "\n",
      "Train loss: 0.07335349917411804\n",
      "Accuracy on training set: 0.9767\n",
      "\n",
      "Validation loss: 0.06628279387950897\n",
      "Accuracy on validation set: 0.9802\n",
      "\n",
      "-> Epoch 22\n",
      "\n",
      "Train loss: 0.07115588337182999\n",
      "Accuracy on training set: 0.9777\n",
      "\n",
      "Validation loss: 0.06961386650800705\n",
      "Accuracy on validation set: 0.9798\n",
      "\n",
      "-> Epoch 23\n",
      "\n",
      "Train loss: 0.07167810201644897\n",
      "Accuracy on training set: 0.9768666666666667\n",
      "\n",
      "Validation loss: 0.07483027875423431\n",
      "Accuracy on validation set: 0.9784\n",
      "\n",
      "-> Epoch 24\n",
      "\n",
      "Train loss: 0.06956733018159866\n",
      "Accuracy on training set: 0.9777333333333335\n",
      "\n",
      "Validation loss: 0.07279723882675171\n",
      "Accuracy on validation set: 0.9803\n",
      "\n",
      "-> Epoch 25\n",
      "\n",
      "Train loss: 0.0696231946349144\n",
      "Accuracy on training set: 0.9776666666666665\n",
      "\n",
      "Validation loss: 0.06952822953462601\n",
      "Accuracy on validation set: 0.9796\n",
      "\n",
      "-> Epoch 26\n",
      "\n",
      "Train loss: 0.06840900331735611\n",
      "Accuracy on training set: 0.9774\n",
      "\n",
      "Validation loss: 0.06813805550336838\n",
      "Accuracy on validation set: 0.9801\n",
      "\n",
      "-> Epoch 27\n",
      "\n",
      "Train loss: 0.06951086968183517\n",
      "Accuracy on training set: 0.9777\n",
      "\n",
      "Validation loss: 0.07250469923019409\n",
      "Accuracy on validation set: 0.9795\n",
      "\n",
      "-> Epoch 28\n",
      "\n",
      "Train loss: 0.06673980504274368\n",
      "Accuracy on training set: 0.9785666666666667\n",
      "\n",
      "Validation loss: 0.07156626880168915\n",
      "Accuracy on validation set: 0.9785\n",
      "\n",
      "-> Epoch 29\n",
      "\n",
      "Train loss: 0.06893780082464218\n",
      "Accuracy on training set: 0.9781166666666666\n",
      "\n",
      "Validation loss: 0.06349650770425797\n",
      "Accuracy on validation set: 0.9802\n",
      "\n",
      "-> Epoch 30\n",
      "\n",
      "Train loss: 0.06456972658634186\n",
      "Accuracy on training set: 0.9790833333333334\n",
      "\n",
      "Validation loss: 0.0664827972650528\n",
      "Accuracy on validation set: 0.9805\n",
      "\n",
      "-> Epoch 31\n",
      "\n",
      "Train loss: 0.06680182367563248\n",
      "Accuracy on training set: 0.9778666666666667\n",
      "\n",
      "Validation loss: 0.06645465642213821\n",
      "Accuracy on validation set: 0.9794\n",
      "\n",
      "-> Epoch 32\n",
      "\n",
      "Train loss: 0.06500072777271271\n",
      "Accuracy on training set: 0.9788\n",
      "\n",
      "Validation loss: 0.06700317561626434\n",
      "Accuracy on validation set: 0.9814\n",
      "\n",
      "-> Epoch 33\n",
      "\n",
      "Train loss: 0.06903676688671112\n",
      "Accuracy on training set: 0.9778666666666667\n",
      "\n",
      "Validation loss: 0.06629405915737152\n",
      "Accuracy on validation set: 0.9803\n",
      "\n",
      "-> Epoch 34\n",
      "\n",
      "Train loss: 0.06396901607513428\n",
      "Accuracy on training set: 0.9798\n",
      "\n",
      "Validation loss: 0.062456730753183365\n",
      "Accuracy on validation set: 0.981\n",
      "\n",
      "-> Epoch 35\n",
      "\n",
      "Train loss: 0.06461179256439209\n",
      "Accuracy on training set: 0.9794333333333335\n",
      "\n",
      "Validation loss: 0.07116236537694931\n",
      "Accuracy on validation set: 0.9805\n",
      "\n",
      "-> Epoch 36\n",
      "\n",
      "Train loss: 0.06445275992155075\n",
      "Accuracy on training set: 0.9793666666666667\n",
      "\n",
      "Validation loss: 0.06388986855745316\n",
      "Accuracy on validation set: 0.9824\n",
      "\n",
      "-> Epoch 37\n",
      "\n",
      "Train loss: 0.06757869571447372\n",
      "Accuracy on training set: 0.9781166666666666\n",
      "\n",
      "Validation loss: 0.06288690865039825\n",
      "Accuracy on validation set: 0.9818\n",
      "\n",
      "-> Epoch 38\n",
      "\n",
      "Train loss: 0.06512730568647385\n",
      "Accuracy on training set: 0.9793499999999998\n",
      "\n",
      "Validation loss: 0.06472811847925186\n",
      "Accuracy on validation set: 0.9808\n",
      "\n",
      "-> Epoch 39\n",
      "\n",
      "Train loss: 0.06308523565530777\n",
      "Accuracy on training set: 0.9802833333333333\n",
      "\n",
      "Validation loss: 0.07287459075450897\n",
      "Accuracy on validation set: 0.9796\n",
      "\n",
      "-> Epoch 40\n",
      "\n",
      "Train loss: 0.06347381323575974\n",
      "Accuracy on training set: 0.9789000000000001\n",
      "\n",
      "Validation loss: 0.06438661366701126\n",
      "Accuracy on validation set: 0.9819\n",
      "\n",
      "-> Epoch 41\n",
      "\n",
      "Train loss: 0.06166616454720497\n",
      "Accuracy on training set: 0.9808666666666667\n",
      "\n",
      "Validation loss: 0.06175598129630089\n",
      "Accuracy on validation set: 0.9815\n",
      "\n",
      "-> Epoch 42\n",
      "\n",
      "Train loss: 0.06330804526805878\n",
      "Accuracy on training set: 0.9793166666666665\n",
      "\n",
      "Validation loss: 0.06900308281183243\n",
      "Accuracy on validation set: 0.9801\n",
      "\n",
      "-> Epoch 43\n",
      "\n",
      "Train loss: 0.06514877080917358\n",
      "Accuracy on training set: 0.9795166666666667\n",
      "\n",
      "Validation loss: 0.06816404312849045\n",
      "Accuracy on validation set: 0.9803\n",
      "\n",
      "-> Epoch 44\n",
      "\n",
      "Train loss: 0.06297416239976883\n",
      "Accuracy on training set: 0.9799333333333334\n",
      "\n",
      "Validation loss: 0.06754570454359055\n",
      "Accuracy on validation set: 0.9816\n",
      "\n",
      "-> Epoch 45\n",
      "\n",
      "Train loss: 0.06078697741031647\n",
      "Accuracy on training set: 0.9803333333333334\n",
      "\n",
      "Validation loss: 0.06419678032398224\n",
      "Accuracy on validation set: 0.9821\n",
      "\n",
      "-> Epoch 46\n",
      "\n",
      "Train loss: 0.06113351881504059\n",
      "Accuracy on training set: 0.9801666666666667\n",
      "\n",
      "Validation loss: 0.06642888486385345\n",
      "Accuracy on validation set: 0.9816\n",
      "\n",
      "-> Epoch 47\n",
      "\n",
      "Train loss: 0.06200524792075157\n",
      "Accuracy on training set: 0.9795833333333334\n",
      "\n",
      "Validation loss: 0.06870364397764206\n",
      "Accuracy on validation set: 0.9807\n",
      "\n",
      "-> Epoch 48\n",
      "\n",
      "Train loss: 0.06451183557510376\n",
      "Accuracy on training set: 0.9783166666666667\n",
      "\n",
      "Validation loss: 0.0646512433886528\n",
      "Accuracy on validation set: 0.9808\n",
      "\n",
      "-> Epoch 49\n",
      "\n",
      "Train loss: 0.062116265296936035\n",
      "Accuracy on training set: 0.9792166666666666\n",
      "\n",
      "Validation loss: 0.06184300035238266\n",
      "Accuracy on validation set: 0.9814\n",
      "\n",
      "-> Epoch 50\n",
      "\n",
      "Train loss: 0.06182149797677994\n",
      "Accuracy on training set: 0.9799000000000001\n",
      "\n",
      "Validation loss: 0.06262323260307312\n",
      "Accuracy on validation set: 0.9813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best model FNN\n",
    "\n",
    "best_score_validation_FFNN = max(scores_hyperpar_FFNN_models, key=operator.itemgetter(1))[0]\n",
    "best_score_accuracy_FFNN = max(scores_hyperpar_FFNN_models, key=operator.itemgetter(1))[1]\n",
    "best_hyperpars_FFNN = max(scores_hyperpar_FFNN_models, key=operator.itemgetter(1))[2]\n",
    "print(\"Best validation and accuracy score:\\n\", best_score_validation_FFNN, best_score_accuracy_FFNN)\n",
    "print(\"\\nBest hyperparameters:\\n\", best_hyperpars_FFNN)\n",
    "\n",
    "\"\"\"### Testing \"\"\"\n",
    "\n",
    "# Training on the entire training dataset and testing on test set\n",
    "\n",
    "FFNN_net = Net(784, best_hyperpars_FFNN[\"Num_hidd_neurons\"], best_hyperpars_FFNN[\"Num_hidd_neurons\"], 10, best_hyperpars_FFNN[\"Act_func\"], best_hyperpars_FFNN[\"Dropout\"])\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # Check if the GPU is available\n",
    "FFNN_net.to(device)\n",
    "optimizer = best_hyperpars_FFNN[\"Optimizer\"](FFNN_net.parameters(), best_hyperpars_FFNN[\"lr\"], weight_decay = best_hyperpars_FFNN[\"Regularizer_L2\"])\n",
    "num_epochs = 50\n",
    "\n",
    "print(\"\\n\\n##### BEST MODEL TRAINING/TESTING #####\\n\")\n",
    "train_losses, accuracy_train_scores, test_losses, accuracy_test_scores = train_function_FFNN(FFNN_net, train_dataloader, test_dataloader, num_epochs, optimizer, FFNN_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL RESULT:\n",
      "Final loss and accuracy for our model: (0.06262323, 0.9813)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_40020\\1159796984.py:18: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss and accuracy plots\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1,ncols=2, figsize=(18,6))\n",
    "ax1.set_title(\"Loss vs epoch\")\n",
    "ax2.set_title(\"Accuracy vs epoch\")\n",
    "ax1.semilogy(train_losses, label='Train loss')\n",
    "ax1.semilogy(test_losses, label='Test loss')\n",
    "plt.semilogy(accuracy_train_scores, label='Train accuracy')\n",
    "plt.semilogy(accuracy_test_scores, label='Test accuracy')\n",
    "ax1.grid(color='lightgrey' , linestyle=':')\n",
    "ax2.grid(color='lightgrey' , linestyle=':')\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nFINAL RESULT:\")\n",
    "print(f\"Final loss and accuracy for our model: {test_losses[-1], accuracy_test_scores[-1]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
